%!PS-Adobe-3.0
%%BoundingBox: 18 36 577 806
%%Title: Enscript Output
%%Creator: GNU Enscript 1.6.5.90
%%CreationDate: Wed Aug 21 15:55:29 2019
%%Orientation: Portrait
%%Pages: (atend)
%%DocumentMedia: A4 595 842 0 () ()
%%DocumentNeededResources: (atend)
%%EndComments
%%BeginProlog
%%BeginResource: procset Enscript-Prolog 1.6.5 90
%
% Procedures.
%

/_S {	% save current state
  /_s save def
} def
/_R {	% restore from saved state
  _s restore
} def

/S {	% showpage protecting gstate
  gsave
  showpage
  grestore
} bind def

/MF {	% fontname newfontname -> -	make a new encoded font
  /newfontname exch def
  /fontname exch def

  /fontdict fontname findfont def
  /newfont fontdict maxlength dict def

  fontdict {
    exch
    dup /FID eq {
      % skip FID pair
      pop pop
    } {
      % copy to the new font dictionary
      exch newfont 3 1 roll put
    } ifelse
  } forall

  newfont /FontName newfontname put

  % insert only valid encoding vectors
  encoding_vector length 256 eq {
    newfont /Encoding encoding_vector put
  } if

  newfontname newfont definefont pop
} def

/MF_PS { % fontname newfontname -> -	make a new font preserving its enc
  /newfontname exch def
  /fontname exch def

  /fontdict fontname findfont def
  /newfont fontdict maxlength dict def

  fontdict {
    exch
    dup /FID eq {
      % skip FID pair
      pop pop
    } {
      % copy to the new font dictionary
      exch newfont 3 1 roll put
    } ifelse
  } forall

  newfont /FontName newfontname put

  newfontname newfont definefont pop
} def

/SF { % fontname width height -> -	set a new font
  /height exch def
  /width exch def

  findfont
  [width 0 0 height 0 0] makefont setfont
} def

/SUF { % fontname width height -> -	set a new user font
  /height exch def
  /width exch def

  /F-gs-user-font MF
  /F-gs-user-font width height SF
} def

/SUF_PS { % fontname width height -> -	set a new user font preserving its enc
  /height exch def
  /width exch def

  /F-gs-user-font MF_PS
  /F-gs-user-font width height SF
} def

/M {moveto} bind def
/s {show} bind def

/Box {	% x y w h -> -			define box path
  /d_h exch def /d_w exch def /d_y exch def /d_x exch def
  d_x d_y  moveto
  d_w 0 rlineto
  0 d_h rlineto
  d_w neg 0 rlineto
  closepath
} def

/bgs {	% x y height blskip gray str -> -	show string with bg color
  /str exch def
  /gray exch def
  /blskip exch def
  /height exch def
  /y exch def
  /x exch def

  gsave
    x y blskip sub str stringwidth pop height Box
    gray setgray
    fill
  grestore
  x y M str s
} def

/bgcs { % x y height blskip red green blue str -> -  show string with bg color
  /str exch def
  /blue exch def
  /green exch def
  /red exch def
  /blskip exch def
  /height exch def
  /y exch def
  /x exch def

  gsave
    x y blskip sub str stringwidth pop height Box
    red green blue setrgbcolor
    fill
  grestore
  x y M str s
} def

% Highlight bars.
/highlight_bars {	% nlines lineheight output_y_margin gray -> -
  gsave
    setgray
    /ymarg exch def
    /lineheight exch def
    /nlines exch def

    % This 2 is just a magic number to sync highlight lines to text.
    0 d_header_y ymarg sub 2 sub translate

    /cw d_output_w cols div def
    /nrows d_output_h ymarg 2 mul sub lineheight div cvi def

    % for each column
    0 1 cols 1 sub {
      cw mul /xp exch def

      % for each rows
      0 1 nrows 1 sub {
        /rn exch def
        rn lineheight mul neg /yp exch def
        rn nlines idiv 2 mod 0 eq {
	  % Draw highlight bar.  4 is just a magic indentation.
	  xp 4 add yp cw 8 sub lineheight neg Box fill
	} if
      } for
    } for

  grestore
} def

% Line highlight bar.
/line_highlight {	% x y width height gray -> -
  gsave
    /gray exch def
    Box gray setgray fill
  grestore
} def

% Column separator lines.
/column_lines {
  gsave
    .1 setlinewidth
    0 d_footer_h translate
    /cw d_output_w cols div def
    1 1 cols 1 sub {
      cw mul 0 moveto
      0 d_output_h rlineto stroke
    } for
  grestore
} def

% Column borders.
/column_borders {
  gsave
    .1 setlinewidth
    0 d_footer_h moveto
    0 d_output_h rlineto
    d_output_w 0 rlineto
    0 d_output_h neg rlineto
    closepath stroke
  grestore
} def

% Do the actual underlay drawing
/draw_underlay {
  ul_style 0 eq {
    ul_str true charpath stroke
  } {
    ul_str show
  } ifelse
} def

% Underlay
/underlay {	% - -> -
  gsave
    0 d_page_h translate
    d_page_h neg d_page_w atan rotate

    ul_gray setgray
    ul_font setfont
    /dw d_page_h dup mul d_page_w dup mul add sqrt def
    ul_str stringwidth pop dw exch sub 2 div ul_h_ptsize -2 div moveto
    draw_underlay
  grestore
} def

/user_underlay {	% - -> -
  gsave
    ul_x ul_y translate
    ul_angle rotate
    ul_gray setgray
    ul_font setfont
    0 0 ul_h_ptsize 2 div sub moveto
    draw_underlay
  grestore
} def

% Page prefeed
/page_prefeed {		% bool -> -
  statusdict /prefeed known {
    statusdict exch /prefeed exch put
  } {
    pop
  } ifelse
} def

% Wrapped line markers
/wrapped_line_mark {	% x y charwith charheight type -> -
  /type exch def
  /h exch def
  /w exch def
  /y exch def
  /x exch def

  type 2 eq {
    % Black boxes (like TeX does)
    gsave
      0 setlinewidth
      x w 4 div add y M
      0 h rlineto w 2 div 0 rlineto 0 h neg rlineto
      closepath fill
    grestore
  } {
    type 3 eq {
      % Small arrows
      gsave
        .2 setlinewidth
        x w 2 div add y h 2 div add M
        w 4 div 0 rlineto
        x w 4 div add y lineto stroke

        x w 4 div add w 8 div add y h 4 div add M
        x w 4 div add y lineto
	w 4 div h 8 div rlineto stroke
      grestore
    } {
      % do nothing
    } ifelse
  } ifelse
} def

% EPSF import.

/BeginEPSF {
  /b4_Inc_state save def    		% Save state for cleanup
  /dict_count countdictstack def	% Count objects on dict stack
  /op_count count 1 sub def		% Count objects on operand stack
  userdict begin
  /showpage { } def
  0 setgray 0 setlinecap
  1 setlinewidth 0 setlinejoin
  10 setmiterlimit [ ] 0 setdash newpath
  /languagelevel where {
    pop languagelevel
    1 ne {
      false setstrokeadjust false setoverprint
    } if
  } if
} bind def

/EndEPSF {
  count op_count sub { pos } repeat	% Clean up stacks
  countdictstack dict_count sub { end } repeat
  b4_Inc_state restore
} bind def

% Check PostScript language level.
/languagelevel where {
  pop /gs_languagelevel languagelevel def
} {
  /gs_languagelevel 1 def
} ifelse
%%EndResource
%%BeginResource: procset Enscript-Encoding-88591 1.6.5 90
/encoding_vector [
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/space        	/exclam       	/quotedbl     	/numbersign   	
/dollar       	/percent      	/ampersand    	/quoteright   	
/parenleft    	/parenright   	/asterisk     	/plus         	
/comma        	/hyphen       	/period       	/slash        	
/zero         	/one          	/two          	/three        	
/four         	/five         	/six          	/seven        	
/eight        	/nine         	/colon        	/semicolon    	
/less         	/equal        	/greater      	/question     	
/at           	/A            	/B            	/C            	
/D            	/E            	/F            	/G            	
/H            	/I            	/J            	/K            	
/L            	/M            	/N            	/O            	
/P            	/Q            	/R            	/S            	
/T            	/U            	/V            	/W            	
/X            	/Y            	/Z            	/bracketleft  	
/backslash    	/bracketright 	/asciicircum  	/underscore   	
/quoteleft    	/a            	/b            	/c            	
/d            	/e            	/f            	/g            	
/h            	/i            	/j            	/k            	
/l            	/m            	/n            	/o            	
/p            	/q            	/r            	/s            	
/t            	/u            	/v            	/w            	
/x            	/y            	/z            	/braceleft    	
/bar          	/braceright   	/tilde        	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/.notdef      	/.notdef      	/.notdef      	/.notdef      	
/space        	/exclamdown   	/cent         	/sterling     	
/currency     	/yen          	/brokenbar    	/section      	
/dieresis     	/copyright    	/ordfeminine  	/guillemotleft	
/logicalnot   	/hyphen       	/registered   	/macron       	
/degree       	/plusminus    	/twosuperior  	/threesuperior	
/acute        	/mu           	/paragraph    	/bullet       	
/cedilla      	/onesuperior  	/ordmasculine 	/guillemotright	
/onequarter   	/onehalf      	/threequarters	/questiondown 	
/Agrave       	/Aacute       	/Acircumflex  	/Atilde       	
/Adieresis    	/Aring        	/AE           	/Ccedilla     	
/Egrave       	/Eacute       	/Ecircumflex  	/Edieresis    	
/Igrave       	/Iacute       	/Icircumflex  	/Idieresis    	
/Eth          	/Ntilde       	/Ograve       	/Oacute       	
/Ocircumflex  	/Otilde       	/Odieresis    	/multiply     	
/Oslash       	/Ugrave       	/Uacute       	/Ucircumflex  	
/Udieresis    	/Yacute       	/Thorn        	/germandbls   	
/agrave       	/aacute       	/acircumflex  	/atilde       	
/adieresis    	/aring        	/ae           	/ccedilla     	
/egrave       	/eacute       	/ecircumflex  	/edieresis    	
/igrave       	/iacute       	/icircumflex  	/idieresis    	
/eth          	/ntilde       	/ograve       	/oacute       	
/ocircumflex  	/otilde       	/odieresis    	/divide       	
/oslash       	/ugrave       	/uacute       	/ucircumflex  	
/udieresis    	/yacute       	/thorn        	/ydieresis    	
] def
%%EndResource
%%EndProlog
%%BeginSetup
%%IncludeResource: font Courier-Bold
%%IncludeResource: font Courier
/HFpt_w 10 def
/HFpt_h 10 def
/Courier-Bold /HF-gs-font MF
/HF /HF-gs-font findfont [HFpt_w 0 0 HFpt_h 0 0] makefont def
/Courier /F-gs-font MF
/F-gs-font 10 10 SF
/#copies 1 def
% Pagedevice definitions:
gs_languagelevel 1 gt {
  <<
    /PageSize [595 842] 
  >> setpagedevice
} if
%%BeginResource: procset Enscript-Header-simple 1.6.5 90

/do_header {	% print default simple header
  gsave
    d_header_x d_header_y HFpt_h 3 div add translate

    HF setfont
    user_header_p {
      5 0 moveto user_header_left_str show

      d_header_w user_header_center_str stringwidth pop sub 2 div
      0 moveto user_header_center_str show

      d_header_w user_header_right_str stringwidth pop sub 5 sub
      0 moveto user_header_right_str show
    } {
      5 0 moveto fname show
      45 0 rmoveto fmodstr show
      45 0 rmoveto pagenumstr show
    } ifelse

  grestore
} def
%%EndResource
/d_page_w 559 def
/d_page_h 770 def
/d_header_x 0 def
/d_header_y 755 def
/d_header_w 559 def
/d_header_h 15 def
/d_footer_x 0 def
/d_footer_y 0 def
/d_footer_w 559 def
/d_footer_h 0 def
/d_output_w 559 def
/d_output_h 755 def
/cols 1 def
%%EndSetup
%%Page: (1) 1
%%BeginPageSetup
_S
18 36 translate
/pagenum 1 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (1) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(NeuronRain is a new linux kernel fork-off from mainline kernel \(presently overlayed on kern) s
5 731 M
(el 4.1.5 32 bit and kernel 4.13.3 64 bit\) augmented with Machine Learning, Analytics, New s) s
5 720 M
(ystem call primitives and Kernel Modules for cloud RPC, Memory and Filesystem. It differs f) s
5 709 M
(rom usual CloudOSes like OpenStack, VMs and containers in following ways:) s
5 698 M
(    \(*\) Mostly available CloudOSes are application layer deployment/provisioning \(YAML etc.) s
5 687 M
(,\) focussed while NeuronRain is not about deploying applications but to bring the cloud fun) s
5 676 M
(ctionality into Linux kernel itself. ) s
5 665 M
(    \(*\) There are application layer memcache softwares available for bigdata processing.) s
5 654 M
(    \(*\) There have been some opensource projects for linux kernel on GitHub to provide memc) s
5 643 M
(ache functionality for kernelspace memory.) s
5 632 M
(    \(*\) NeuronRain VIRGO32 and VIRGO64 kernels have new system calls and kernel drivers for) s
5 621 M
( remote cloning a process, memcache kernel memory and remote file I/O with added advantage ) s
5 610 M
(of reading analytics variables in kernel.) s
5 599 M
(    \(*\) Cloud RPCs, Cloud Kernel Memcache and Filesystems are implemented in Linux kernel w) s
5 588 M
(ith kernelspace sockets) s
5 577 M
(    \(*\) Linux kernel has access to Machine Learnt Analytics\(in AsFer\) with VIRGO linux kern) s
5 566 M
(el_analytics driver) s
5 555 M
(    \(*\) Assumes already encrypted data for traffic between kernels on different machines.) s
5 544 M
(    \(*\) Advantages of kernelspace Cloud implementation are: Remote Device Invocation \(recen) s
5 533 M
(tly known as Internet of Things\), Mobile device clouds, High performance etc.,.) s
5 522 M
(    \(*\) NeuronRain is not about VM/Containerization but VMs, CloudOSes and Containers can b) s
5 511 M
(e optionally rewritten by invoking NeuronRain VIRGO systemcalls and drivers - thus NeuronRa) s
5 500 M
(in Linux kernel is the bottommost layer beneath VMs, Containers, CloudOSes.) s
5 489 M
(    \(*\) Partially inspired by old Linux Kernel components - Remote Device Invocation and Su) s
5 478 M
(nRPC) s
5 467 M
(    \(*\) VIRGO64 kernel based on 4.13.3 mainline kernel, which is 64 bit version of VIRGO32,) s
5 456 M
( has lot of stability/panic issues resolved which were random and frequent in VIRGO32 and h) s
5 445 M
(as Kernel Transport Layer Security \(KTLS\) integrated into kernel tree.) s
5 423 M
(NeuronRain - Repositories:) s
5 412 M
(--------------------------) s
5 401 M
(NeuronRain repositories are in:) s
5 379 M
(        \(*\) NeuronRain Research - http://sourceforge.net/users/ka_shrinivaasan - astronomy ) s
5 368 M
(datasets) s
5 346 M
(        \(*\) NeuronRain Green - https://github.com/shrinivaasanka - generic datasets) s
5 335 M
(        \(replicated in https://gitlab.com/shrinivaasanka\)) s
5 313 M
(NeuronRain Documentation Repositories:) s
5 302 M
(--------------------------------------) s
5 291 M
(        \(*\) https://github.com/shrinivaasanka/Krishna_iResearch_DoxygenDocs) s
5 269 M
(        \(*\) https://gitlab.com/shrinivaasanka/Krishna_iResearch_DoxygenDocs) s
5 247 M
(        \(*\) https://sourceforge.net/u/userid-769929/Krishna_iResearch_DoxygenDocs/ci/master) s
5 236 M
(/tree/) s
5 214 M
(NeuronRain Version:) s
5 203 M
(-------------------) s
5 192 M
(Previously, each NeuronRain repository source in SourceForge, GitHub and GitLab was snapsho) s
5 181 M
(tted periodically by a version number convention <year>.<month>.<day>. Because total number) s
5 170 M
( of repositories in NeuronRain spread across SourceForge, GitHub and GitLab is huge, releas) s
5 159 M
(e tagging each repository is arduous and therefore individual repository source tagging is ) s
5 148 M
(hereinafter discontinued. Every NeuronRain source code releasefor SourceForge,GitHub and Gi) s
5 137 M
(tLab repositories henceforth would be notified in this documentation page and latest commit) s
5 126 M
( on the date of release \(inferred from <year>.<month>.<day>\) has to be construed as the lat) s
5 115 M
(est source release. Latest NeuronRain Research and Green version is 19.08.20. ) s
5 104 M
(   ) s
5 93 M
(NeuronRain - Features:) s
5 82 M
(----------------------) s
5 71 M
(**VIRGO system calls from include/linux/syscalls.h**) s
5 49 M
(asmlinkage long sys_virgo_clone\(char* func, void *child_stack, int flags, void *arg\);) s
5 27 M
(asmlinkage long sys_virgo_malloc\(int size,unsigned long long __user *vuid\);) s
5 5 M
(asmlinkage long sys_virgo_set\(unsigned long long vuid, const char __user *data_in\);) s
_R
S
%%Page: (2) 2
%%BeginPageSetup
_S
18 36 translate
/pagenum 2 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (2) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 731 M
(asmlinkage long sys_virgo_get\(unsigned long long vuid, char __user *data_out\);) s
5 709 M
(asmlinkage long sys_virgo_free\(unsigned long long vuid\);) s
5 687 M
(asmlinkage long sys_virgo_open\(char* filepath\);) s
5 665 M
(asmlinkage long sys_virgo_read\(long vfsdesc, char __user *data_out, int size, int pos\);) s
5 643 M
(asmlinkage long sys_virgo_write\(long vfsdesc, const char __user *data_in, int size, int pos) s
5 632 M
(\);) s
5 610 M
(asmlinkage long sys_virgo_close\(long vfsdesc\);) s
5 577 M
(**VIRGO Kernel Modules in drivers/virgo**) s
5 555 M
(1. cpupooling virtualization - VIRGO_clone\(\) system call and VIRGO cpupooling driver by whi) s
5 544 M
(ch a remote procedure can be invoked in kernelspace.\(port: 10000\)) s
5 522 M
(2. memorypooling virtualization - VIRGO_malloc\(\), VIRGO_get\(\), VIRGO_set\(\), VIRGO_free\(\) sy) s
5 511 M
(stem calls and VIRGO memorypooling driver by which kernel memory can be allocated in remote) s
5 500 M
( node, written to, read and freed - A kernelspace memcache-ing.\(port: 30000\)) s
5 478 M
(3. filesystem virtualization - VIRGO_open\(\), VIRGO_read\(\), VIRGO_write\(\), VIRGO_close\(\) sys) s
5 467 M
(tem calls and VIRGO cloud filesystem driver by which file IO in remote node can be done in ) s
5 456 M
(kernelspace.\(port: 50000\)) s
5 434 M
(4. config - VIRGO config driver for configuration symbols export.) s
5 412 M
(5. queueing - VIRGO Queuing driver kernel service for queuing incoming requests, handle the) s
5 401 M
(m with workqueue and invoke KingCobra service routines in kernelspace. \(port: 60000\)) s
5 379 M
(6. cloudsync - kernel module for synchronization primitives \(Bakery algorithm etc.,\) with e) s
5 368 M
(xported symbols that can be used in other VIRGO cloud modules for critical section lock\(\) a) s
5 357 M
(nd unlock\(\)) s
5 335 M
(7. utils - utility driver that exports miscellaneous kernel functions that can be used acro) s
5 324 M
(ss VIRGO Linux kernel) s
5 302 M
(8. EventNet - eventnet kernel driver to vfs_read\(\)/vfs_write\(\) text files for EventNet vert) s
5 291 M
(ex and edge messages \(port: 20000\)) s
5 269 M
(9. Kernel_Analytics - kernel module that reads machine-learnt config key-value pairs set in) s
5 258 M
( /etc/virgo_kernel_analytics.conf \(and from a remote cloud as stream of key-value pairs in ) s
5 247 M
(VIRGO64\). Any machine learning software can be used to get the key-value pairs for the conf) s
5 236 M
(ig. This merges three facets - Machine Learning, Cloud Modules in VIRGO Linux-KingCobra-USB) s
5 225 M
(md , Mainline Linux Kernel) s
5 203 M
(10. SATURN program analysis wrapper driver.) s
5 181 M
(11. KTLS config driver - for Kernel Transport Layer Security - only in VIRGO_KTLS branch of) s
5 170 M
( VIRGO64 repositories) s
5 148 M
(Apart from aforementioned drivers, PXRC flight controller and UVC video drivers from kernel) s
5 137 M
( 5.1.4 have been changed to import kernel_analytics exported analytics variables and commit) s
5 126 M
(ted to VIRGO64.) s
5 104 M
(Complete list of Features of NeuronRain \(Research and Enterprise\) are detailed in:) s
5 93 M
(https://sites.google.com/site/kuja27/CV_of_SrinivasanKannan_alias_KaShrinivaasan_alias_Shri) s
5 82 M
(nivasKannan.pdf) s
5 71 M
(https://github.com/shrinivaasanka/Krishna_iResearch_DoxygenDocs/blob/master/kuja27_website_) s
5 60 M
(mirrored/site/kuja27/CV_of_SrinivasanKannan_alias_KaShrinivaasan_alias_ShrinivasKannan.pdf) s
5 38 M
(Previous system calls and drivers do not have internal mutexes and synchronization is left ) s
5 27 M
(to the userspace. Quoting Commit Notes from hash https://github.com/shrinivaasanka/virgo64-) s
5 16 M
(linux-github-code/commit/ad59cbb0bec23ced72109f8c5a63338d1fd84beb :) s
5 5 M
("... Note on concurrency: Presently mutexing within system calls have been commented becaus) s
_R
S
%%Page: (3) 3
%%BeginPageSetup
_S
18 36 translate
/pagenum 3 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (3) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(e in past linux versions mutexing within kernel was causing strange panic issues. As a desi) s
5 731 M
(gn choice and feature-stability tradeoff \(stability is more important than introducing addi) s
5 720 M
(tional code\) mutexing has been lifted up to userspace. It is upto the user applications inv) s
5 709 M
(oking the system calls to synchronize multiple user threads invoking VIRGO64 system calls i) s
5 698 M
(.e VIRGO64 system calls are not re-entrant. This would allow just one kernel thread \(mapped) s
5 687 M
( 1:1 to a user thread\) to execute in kernel space. Mostly this is relevant only to kmemcach) s
5 676 M
(e system calls which have global in-kernel-memory address translation tables and next_id va) s
5 665 M
(riable. VIRGO clone/filesystem calls do not have global in-kernel-memory datastructures. ..) s
5 654 M
(.". An example pthread mutex code doing VIRGO64 system calls invocation in 2 parallel concu) s
5 643 M
(rrent processes within a critical section lock/unlock is at https://github.com/shrinivaasan) s
5 632 M
(ka/virgo64-linux-github-code/blob/master/linux-kernel-extensions/virgo_malloc/test/test_vir) s
5 621 M
(go_malloc.c. Synchronization in userspace for system calls-drivers RPC is easier to analyze) s
5 610 M
( and modify user application code if there are concurrency issues than locking within kerne) s
5 599 M
(lspace in system calls and drivers. This would also remove redundant double locking in user) s
5 588 M
(space and kernelspace. Another advantage of doing synchronization in userspace is the flexi) s
5 577 M
(bility in granularity of the critical section - User can decide when to lock and unlock acc) s
5 566 M
(ess to a resource e.g permutations of malloc/set/get/free kmemcache primitive sequences can) s
5 555 M
( be synchronized as desired by an application.) s
5 533 M
(NeuronRain - Architecture Diagrams:) s
5 522 M
(-----------------------------------) s
5 511 M
(.. image:: NeuronRainVIRGOArchitecture.jpg) s
5 500 M
(https://github.com/shrinivaasanka/Krishna_iResearch_DoxygenDocs/blob/master/Krishna_iResear) s
5 489 M
(ch_opensourceproducts_archdiagram.pdf) s
5 478 M
(https://github.com/shrinivaasanka/Krishna_iResearch_DoxygenDocs/blob/master/NeuronRain_Arch) s
5 467 M
(itecture_Diagrams_29September2016.pdf) s
5 445 M
(Products in NeuronRain Suite \(Research and Green\):) s
5 434 M
(------------------------------------------------------) s
5 423 M
(AsFer - AstroInfer was initially intended, as the name suggests, for pattern mining of Astr) s
5 412 M
(onomical Datasets to predict natural weather disasters. It is focussed on mining patterns i) s
5 401 M
(n texts and strings. It also has implementations of algorithms for analyzing merit of text,) s
5 390 M
( PAC learning, Polynomial reconstruction, List decoding, Factorization etc., which are late) s
5 379 M
(r expansions of publications by the author \(K.Srinivasan - http://dblp.dagstuhl.de/pers/hd/) s
5 368 M
(s/Shrinivaasan:Ka=\) after 2012. Presently AsFer in SourceForge, GitHub and GitLab has imple) s
5 357 M
(mentations for prominently used machine learning algorithms.) s
5 335 M
(USBmd - Wireless data traffic and USB analytics - analyzes internet traffic and USB URB dat) s
5 324 M
(a packets for patterns by AsFer machine learning \(e.g FTrace, USBmon, Wireshark/Tcpdump PCA) s
5 313 M
(P, USBWWAN and kern.log Spark MapReduce\) implementations and Graph theoretic algorithms on ) s
5 302 M
(kernel function call graphs. It is also a module in VIRGO linux kernel.) s
5 280 M
(VIRGO Linux Kernel - Linux kernel fork-off based on 4.1.5 \(32 bit\) and 4.13.3 \(64 bit\) has ) s
5 269 M
(new system calls and drivers which abstract cloud RPC, kernel memcache and Filesystem. Thes) s
5 258 M
(e system calls are kernelspace socket clients to kernelspace listeners modules for RPC,Kern) s
5 247 M
(elspace Memory Cacheing and Cloud Filesystems. These new system calls can be invoked by use) s
5 236 M
(r applications written in languages other than C and C++ also \(e.g. Python\). Simply put VIR) s
5 225 M
(GO is a kernelspace cloud while present cloud OSes concentrate on userspace applications. A) s
5 214 M
(pplications on VIRGO kernel are transparent to how cloud RPC works in kernel. This pushes d) s
5 203 M
(own the application layer socket transport to the kernelspace and applications need not inv) s
5 192 M
(oke any userspace cloud libraries e.g make REST http GET/POST requests by explicitly specif) s
5 181 M
(ying hosts in URL. Most of the cloud webservice applications use REST for invoking a remote) s
5 170 M
( service and response is returned as JSON. This is no longer required in VIRGO linux kernel) s
5 159 M
(. Application code is just needed to invoke VIRGO system calls, and kernel internally loadb) s
5 148 M
(alances the requests to cloud nodes based on config files. VIRGO system call clients and dr) s
5 137 M
(iver listeners converse in TCP kernelspace sockets. Responses from remote nodes are present) s
5 126 M
(ly plain texts and can be made as JSON responses optionally. Secure kernel socket families ) s
5 115 M
(like AF_KTLS are available as separate linux forks. If AF_KTLS is in mainline, all socket f) s
5 104 M
(amilies used in VIRGO kernel code can be changed to AF_KTLS from AF_INET and thus security ) s
5 93 M
(is implicit. VIRGO cloud is defined by config files \(virgo_client.conf and virgo_cloud.conf) s
5 82 M
(\) containing comma separated list of IP addresses in constituent machines of the cloud abst) s
5 71 M
(racted from userspace. It also has a kernel_analytics module that reads periodically comput) s
5 60 M
(ed key-value pairs from AsFer and publishes as global symbols within kernel. Any kernel dri) s
5 49 M
(ver including network, I/O, display, paging, scheduler etc., can read these analytics varia) s
5 38 M
(bles and dynamically change kernel behaviour. Good example of userspace cloud library and R) s
5 27 M
(PC is gRPC - https://developers.googleblog.com/2015/02/introducing-grpc-new-open-source-htt) s
5 16 M
(p2.html which is a recent cloud RPC standard from Google. There have been debates on RPC ve) s
5 5 M
(rsus REST in cloud community. REST is stateless protocol and on a request the server copies) s
_R
S
%%Page: (4) 4
%%BeginPageSetup
_S
18 36 translate
/pagenum 4 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (4) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
( its "state" to the remote client. RPC is a remote procedure invocation protocol relying on) s
5 731 M
( serialization of objects. Both REST and RPC are implemented on HTTP by industry standard p) s
5 720 M
(roducts with some variations in syntaxes of the resource URL endpoints. VIRGO linux kernel ) s
5 709 M
(does not care about how requests are done i.e REST or RPC but where the requests are done i) s
5 698 M
(.e in userspace or kernelspace and prefers kernelspace TCP request-response transport. In t) s
5 687 M
(his context it differs from traditional REST and RPC based cloud - REST or RPC are userspac) s
5 676 M
(e wrappers and both internally have to go through TCP, and VIRGO kernel optimizes this TCP ) s
5 665 M
(bottleneck. Pushing down cloud transport primitives to kernel away from userspace should th) s
5 654 M
(eoretically be faster because ) s
5 643 M
(        \(*\) cloud transport is initiated lazy deep into kernel and not in userspace which s) s
5 632 M
(aves serialization slowdown) s
5 621 M
(        \(*\) lot of wrapper application layer overheads like HTTP, HTTPS SSL handshakes are ) s
5 610 M
(replaced by TCP transport layer security \(assuming AF_KTLS sockets\)) s
5 599 M
(        \(*\) disk I/O in VIRGO file system system-calls and driver is done in kernelspace cl) s
5 588 M
(oser to disk than userspace - userspace clouds often require file persistence) s
5 577 M
(        \(*\) repetitive system call invocations in userspace cloud libraries which cause fre) s
5 566 M
(quent userspace-kernerspace switches are removed.) s
5 555 M
(        \(*\) best suited for interacting with remote devices than remote servers because dir) s
5 544 M
(ect kernelspace-kernelspace remote device communication is possible with no interleaved swi) s
5 533 M
(tches to userspace. This makes it ideal for IoT.) s
5 522 M
(        \(*\) VIRGO kernel memcache system-calls and driver facilitate abstraction of kernels) s
5 511 M
(paces of all cloud nodes into single VIRGO kernel addresspace.) s
5 500 M
(        \(*\) VIRGO clone system-call and driver enable execution of a remote binary or a fun) s
5 489 M
(ction in kernelspace i.e kernelspace RPC) s
5 478 M
(An up-to-date description of how RPC ruled the roost, fell out of favour and reincarnated i) s
5 467 M
(n latest cloud standards like Finagle/Thrift/gRPC is in http://dist-prog-book.com/chapter/1) s
5 456 M
(/rpc.html - RPC is Not Dead: Rise, Fall and the Rise of Remote Procedure Calls. All these r) s
5 445 M
(ecent RPC advances are in userspace while VIRGO linux kernel abstracts RPC and loadbalancin) s
5 434 M
(g within system calls itself requiring no user intervention \(it is more than mere Remote Pr) s
5 423 M
(ocedure Call - a lightweight Remote Resource System Call - a new paradigm in itself\).) s
5 401 M
(KingCobra - This is a VIRGO module and implements message queueing and pub-sub model in ker) s
5 390 M
(nelspace. This also has a userspace facet for computational economics \(Pricing, Electronic ) s
5 379 M
(money protocol buffer implementation etc.,\)) s
5 346 M
(NeuronRain Green - Design Documents \(repositories suffixed 64 are for 64-bit and others are) s
5 335 M
( 32-bit on different linux versions\)) s
5 324 M
(------------------------------------------------------------------------------------------) s
5 313 M
(AsFer - https://github.com/shrinivaasanka/asfer-github-code/blob/master/asfer-docs/AstroInf) s
5 302 M
(erDesign.txt) s
5 280 M
(USBmd - https://github.com/shrinivaasanka/usb-md-github-code/blob/master/USBmd_notes.txt) s
5 258 M
(USBmd64 - https://github.com/shrinivaasanka/usb-md64-github-code/blob/master/USBmd_notes.tx) s
5 247 M
(t) s
5 225 M
(VIRGO Linux - https://github.com/shrinivaasanka/virgo-linux-github-code/blob/master/virgo-d) s
5 214 M
(ocs/VirgoDesign.txt) s
5 192 M
(VIRGO64 Linux - https://github.com/shrinivaasanka/virgo64-linux-github-code/blob/master/vir) s
5 181 M
(go-docs/VirgoDesign.txt) s
5 159 M
(KingCobra - https://github.com/shrinivaasanka/kingcobra-github-code/blob/master/KingCobraDe) s
5 148 M
(signNotes.txt) s
5 126 M
(KingCobra64 - https://github.com/shrinivaasanka/kingcobra64-github-code/blob/master/KingCob) s
5 115 M
(raDesignNotes.txt) s
5 93 M
(NeuronRain Research - Design Documents \(repositories suffixed 64 are for 64-bit and others ) s
5 82 M
(are 32-bit on different linux versions\)) s
5 71 M
(---------------------------------------------------------------------------------------) s
5 60 M
(AsFer - https://sourceforge.net/p/asfer/code/HEAD/tree/asfer-docs/AstroInferDesign.txt) s
5 38 M
(USBmd - https://sourceforge.net/p/usb-md/code-0/HEAD/tree/USBmd_notes.txt) s
5 16 M
(USBmd64 - https://sourceforge.net/p/usb-md64/code/ci/master/tree/USBmd_notes.txt) s
_R
S
%%Page: (5) 5
%%BeginPageSetup
_S
18 36 translate
/pagenum 5 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (5) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(VIRGO Linux - https://sourceforge.net/p/virgo-linux/code-0/HEAD/tree/trunk/virgo-docs/Virgo) s
5 731 M
(Design.txt) s
5 709 M
(VIRGO64 Linux - https://sourceforge.net/p/virgo64-linux/code/ci/master/tree/virgo-docs/Virg) s
5 698 M
(oDesign.txt) s
5 676 M
(KingCobra - https://sourceforge.net/p/kcobra/code-svn/HEAD/tree/KingCobraDesignNotes.txt) s
5 654 M
(KingCobra64 - https://sourceforge.net/p/kcobra64/code/ci/master/tree/KingCobraDesignNotes.t) s
5 643 M
(xt) s
5 621 M
(Some Implementations in AsFer in GitLab, GitHub and Sourceforge are related to publications) s
5 610 M
( in https://scholar.google.co.in/citations?hl=en&user=eLZY7CIAAAAJ and publication drafts i) s
5 599 M
(n https://sites.google.com/site/kuja27/ and https://sourceforge.net/projects/acadpdrafts/fi) s
5 588 M
(les/) s
5 566 M
(Free course material in https://github.com/shrinivaasanka/Grafit and GitLab also refer to i) s
5 555 M
(mplementations in previous NeuronRain GitHub, GitLab and Sourceforge respositories. Some of) s
5 544 M
( GRAFIT GitHub and GitLab course material link to complementary course notes in https://kuj) s
5 533 M
(a27.blogspot.in which is meant for expository graphics for the course material and audio-vi) s
5 522 M
(sual lectures, if necessary.) s
5 489 M
(FAQ) s
5 478 M
(---) s
5 467 M
(**What is the meaning of name "NeuronRain"?**) s
5 445 M
(Earlier the repositories in GitHub and SourceForge were named "iCloud" but it was in confli) s
5 434 M
(ct with an already existing mobile cloud platform. Hence different name had to be chosen. A) s
5 423 M
(ll these codebases are targeted at a machine learning powered cloud. AsFer implements almos) s
5 412 M
(t all prominent machine learning and deep learning neural network algorithms among others. ) s
5 401 M
(It was intended to be named "NeuronCloud" but because of astronomical weather forecasting o) s
5 390 M
(rigins \(both have clouds - weather and linux\), and rain realises cloud, it has been named ") s
5 379 M
(NeuronRain".) s
5 357 M
(**How does machine learning help in predicting weather vagaries? How does NeuronRain resear) s
5 346 M
(ch version approach this?**) s
5 324 M
(It is an unusual application of machine learning to predict weather from astronomical data.) s
5 313 M
( Disclaimer here is this is not astrology but astronomy. It is long known that earth is inf) s
5 302 M
(luenced by gravitational forces of nearby ethereal bodies \(e.g high tides associated with l) s
5 291 M
(unar activity, ElNino-LaNina pairs correlated to Sun spot cycles and Solar maxima etc.,\). N) s
5 280 M
(euronRain research version in SourceForge uses Swiss Ephemeris \(based on NASA JPL Ephemeris) s
5 269 M
( - http://ssd.jpl.nasa.gov/horizons.cgi\) implementation in a third-party opensource code \(M) s
5 258 M
(aitreya's Dreams\) to compute celestial degree locations of planets in Solar system. It mine) s
5 247 M
(s historic data of weather disasters \(Typhoons, Hurricanes, Earthquakes\) for patterns in as) s
5 236 M
(tronomical positions of celestial bodies and their connections to heightened weather distur) s
5 225 M
(bances on earth. Prominent algorithm used is sequence mining which finds common patterns in) s
5 214 M
( string encoded celestial information. This sequence mining along with other bioinformatics) s
5 203 M
( tools extracts class association rules for weather patterns. Preliminary analysis shows th) s
5 192 M
(is kind of pattern mining of astronomical data coincides reasonably with actual observation) s
5 181 M
(s. There is a python script in asfer codebase which iterates through sequence mined rules a) s
5 170 M
(nd searches a celestial configuration matching it. Most weather models are fluid dynamics b) s
5 159 M
(ased while this is a non-conventional astronomy based analysis. Gravitational influences am) s
5 148 M
(ongst celestial bodies and their resultant orbital vicissitudes are formulated by set of di) s
5 137 M
(fferential equations and solutions to them known as N-Body Problem \(http://en.wikipedia.org) s
5 126 M
(/wiki/N-body_problem\). Solar system is a set of celestial bodies with mutual gravitational ) s
5 115 M
(influences. Sequence mining of string encoded celestial configurations, mines patterns in p) s
5 104 M
(lanetary conjunctions \(http://en.wikipedia.org/wiki/Conjunction_\(astronomy\)\) vis-a-vis weat) s
5 93 M
(her/geological vagaries on earth. Each such pattern is an instance of N-Body problem and it) s
5 82 M
(s solutions pertain to gravitational influences for such a celestial configuration. Solving) s
5 71 M
( N-Body problem for N > 3 is non-trivial and no easy solutions are known. Solar system in t) s
5 60 M
(his respect is 9-Body problem of 9 known planets and their mutual gravitational influences ) s
5 49 M
(affecting Earth, ignoring asteroids/comets/KuiperBeltObjects. Thus machine learning helps i) s
5 38 M
(n solving N-Body problem indirectly by mining patterns in planetary positions and how they ) s
5 27 M
(correlate to gravity induced events on Earth obviating N-Body differential equations. Discl) s
5 16 M
(aimer is this kind of forecast drastically differs from conventions and it does not prove b) s
5 5 M
(ut only correlates astronomical gravity influences and events on Earth. Proof requires solv) s
_R
S
%%Page: (6) 6
%%BeginPageSetup
_S
18 36 translate
/pagenum 6 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (6) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(ing the differential equations for N-Body and match them with mined celestial patterns whic) s
5 731 M
(h is daunting. As mentioned earlier, preliminary mined correlation analysis shows emergence) s
5 720 M
( of similar celestial conjunction patterns for similar genre of terrestrial events. Meaning) s
5 709 M
( of celestial bodies named Rahu and Ketu is the imaginary Lunar nodes \(http://en.wikipedia.) s
5 698 M
(org/wiki/Lunar_node\) which are points on zodiac where Ecliptic of the Sun \(path of Sun obse) s
5 687 M
(rved from earth\) crosses the Path of Moon which happens approximately 2*\(12 or 13\) times pe) s
5 676 M
(r year.) s
5 654 M
(**Is it possible to do accurate long term weather forecasting? Are there theoretical limita) s
5 643 M
(tions? How does NeuronRain weather forecast overcome it?**) s
5 621 M
(No and Yes. Both N-Body problem of solar system and failure of long term weather forecast h) s
5 610 M
(ave their basis in Chaos theory e.g Poincare Maps for 3-body problems define chaos in the o) s
5 599 M
(rbits in system of 3 bodies while Lorenz attractors depict sensitive dependence on initial ) s
5 588 M
(conditions specifically in weather forecast \(Butterfly effect\). This presents a natural lim) s
5 577 M
(itation. All existing weather models suffer due to Chaos. But NeuronRain does not have any ) s
5 566 M
(Chaos theoretic limitation. It just mines patterns in sky and tries to correlate them with ) s
5 555 M
(weather events on earth accuracy of which depends on how the pattern-event correlations mat) s
5 544 M
(ch solutions to N-Body problem. N-Body problem rests on Newtons's Law of Gravitation. It is) s
5 533 M
( not just gravity but electromagnetic fields of other celestial objects also influence eart) s
5 522 M
(h. So it is not exact astrophysics but computational learning model for astrophysics with f) s
5 511 M
(ailure probability.) s
5 489 M
(**Can you cite an example machine learnt celestial pattern correlated to a terrestrial even) s
5 478 M
(t?**) s
5 456 M
(Sequence Mined Class Association Rules in http://sourceforge.net/p/asfer/code/HEAD/tree/pyt) s
5 445 M
(hon-src/MinedClassAssociationRules.txt and http://github.com/shrinivaasanka/asfer-github-co) s
5 434 M
(de/blob/master/python-src/MinedClassAssociationRules.txt created by SequenceMining of strin) s
5 423 M
(g encoded celestial configuration show prominent celestial conjunctions when large magnitud) s
5 412 M
(e Earthquakes or Hurricanes occur. One of the mined rule is Sun + Moon also known as New Mo) s
5 401 M
(on. High probability of earthquakes due to Moon's gravitational effects during New Moon day) s
5 390 M
(s \(especially eclipses when Earth-Sun-Moon are aligned in line\) is known \(http://www.scient) s
5 379 M
(ificamerican.com/article/moon-s-gravity-linked-to-big-earthquakes/\). Other prominent mined ) s
5 368 M
(rule is juxtaposition of Mercury-Sun-Venus \(intercuspal and intracuspal\) which highly corre) s
5 357 M
(lates to heightened hurricane-typhoon-tropical cyclone events. Sun-Moon factor influencing ) s
5 346 M
(ocean currents and causing earthquakes is plausible and known but Mercury-Venus, which are ) s
5 335 M
(distant celestial systems having negligible gravitational effects, affecting tropical monso) s
5 324 M
(ons is an intriguing coincidental pattern. Likely explanation is: Mercury-Sun-Venus-Earth i) s
5 313 M
(s a 4 body system. Mercury is always +/-15 degrees approximately from Sun and Venus is alwa) s
5 302 M
(ys +/- 60 degrees approximately from Sun on the zodiac. This 4 body system which is close t) s
5 291 M
(o earth is quite periodic almost annually exerting gravitational influence. Similar explana) s
5 280 M
(tion holds for Mars-Earth et al system too. ) s
5 258 M
(**What is the historic timeline evolution of NeuronRain repositories?**) s
5 236 M
(Initial design of a cognitive inference model \(uncommitted\) was during 2003 though original) s
5 225 M
( conceptualization occurred during 1998-99 to design a distributed linux. Coincidentally, a) s
5 214 M
(n engineering team project done by the author was aligned in this direction - a distributed) s
5 203 M
( cloud-like execution system - though based on application layer CORBA \(https://sourceforge) s
5 192 M
(.net/projects/acadpdrafts/files/Excerpts_Of_PSG_BE_FinalProject_COBRA_done_in_1999.pdf/down) s
5 181 M
(load\). Since 1999, author has worked in various IT companies \(https://sourceforge.net/proje) s
5 170 M
(cts/acadpdrafts/files/AllRelievingLetters.pdf/download\) and studied further \(MSc and an inc) s
5 159 M
(omplete PhD at CMI/IMSc/IIT,Chennai,India - 2008-2011\). It was a later thought to merge mac) s
5 148 M
(hine learning analytics and a distributed linux kernel into a new linux fork-off driven by ) s
5 137 M
(BigData analytics. Commits into Sourceforge and GitHub repositories are chequered with full) s
5 126 M
(time Work and Study tenures. Thus it is pretty much parallel charity effort from 2003 along) s
5 115 M
(side mainstream official work. Presently author does not work for any and works fulltime on) s
5 104 M
( NeuronRain code commits and related independent academic research only with no monetary be) s
5 93 M
(nefit accrued. Significant commits have been done from 2013 onwards and include implementat) s
5 82 M
(ions for author's publications done till 2011 and significant expansion of them done after ) s
5 71 M
(2012 till present. Initially AstroInfer was intended for pattern mining Astronomical Datase) s
5 60 M
(ts for weather prediction. In 2015, NeuronRain was replicated in SourceForge and GitHub aft) s
5 49 M
(er a SourceForge outage and since then SourceForge NeuronRain repos have been made speciali) s
5 38 M
(zed for academic research and astronomy while GitHub NeuronRain repos are for production cl) s
5 27 M
(oud deployments.) s
5 5 M
(**Why is NeuronRain code separated into multiple repositories?**) s
_R
S
%%Page: (7) 7
%%BeginPageSetup
_S
18 36 translate
/pagenum 7 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (7) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 731 M
(Reason is NeuronRain integrates multiple worlds into one and it was difficult to manage the) s
5 720 M
(m in single repository - AsFer implements only userspace machine learning, USBmd is only fo) s
5 709 M
(r USB and WLAN debugging, VIRGO kernel is specially for new systemcalls and drivers, KingCo) s
5 698 M
(bra is for kernelspace messaging/pubsub. Intent was to enable end-user to use any of the re) s
5 687 M
(positories independent of the other. But the boundaries among them have vanished as below:) s
5 676 M
(        \(*\) AsFer invokes VIRGO systemcalls) s
5 665 M
(        \(*\) AsFer implements publications and drafts in acadpdrafts) s
5 654 M
(        \(*\) USBmd invokes AsFer machine learning) s
5 643 M
(        \(*\) VIRGO Queueing forwards to KingCobra) s
5 632 M
(        \(*\) VIRGO is dependent on AsFer for kernel analytics) s
5 621 M
(        \(*\) KingCobra is dependent on AsFer MAC Protocol Buffer currency implementation) s
5 610 M
(        \(*\) Grafit course materials refer to all these repositories) s
5 599 M
(and all NeuronRain repositories are strongly interdependent now. Each repository of NeuronR) s
5 588 M
(ain can be deployed independent of the other - for example, VIRGO linux kernel and kernel_a) s
5 577 M
(nalytics module in it can learn analytic variables from any other third-party Machine Learn) s
5 566 M
(ing framework not necessarily from AstroInfer - TensorFlow, Weka, RapidMiner etc., Only pre) s
5 555 M
(requisite is /etc/kernel_analytics.conf should be periodically updated by set of key-value ) s
5 544 M
(pairs of machine-learnt analytic variables written to it. But flipside of using third-party) s
5 533 M
( machine-learning software in lieu of AsFer is lack of implementations specialized and opti) s
5 522 M
(mized for NeuronRain.) s
5 500 M
(**NeuronRain repositories have implementations for your publications and drafts. Are they r) s
5 489 M
(eviewed? Could you explain about them?**) s
5 467 M
(Only arXiv articles and TAC 2010 publications below are reviewed and guided by faculty - Pr) s
5 456 M
(ofs.Balaraman Ravindran\(IIT,Chennai\), Madhavan Mukund\(CMI\) and Meena Mahajan \(IMSc\) [Co-Aut) s
5 445 M
(hors in https://scholar.google.co.in/citations?hl=en&user=eLZY7CIAAAAJ] while the author wa) s
5 434 M
(s doing PhD till 2011 in CMI/IMSc/IIT,Chennai:) s
5 423 M
(\342\\200\242 Decidability of Complementation - http://arxiv.org/abs/1106.4102) s
5 412 M
(\342\\200\242 Algorithms for Intrinsic Merit - http://arxiv.org/abs/1006.4458) s
5 401 M
(\342\\200\242 NIST TAC 2010 version of Algorithms for Intrinsic Merit - http://www.nist.gov/tac/pu) s
5 390 M
(blications/2010/participant.papers/CMI_IIT.proceedings.pdf) s
5 368 M
(All other draft write-ups in NeuronRain design documents and http://sites.google.com/site/k) s
5 357 M
(uja27 are unreviewed and unguided and were written by the author \(K.Srinivasan - https://si) s
5 346 M
(tes.google.com/site/kuja27/ - presently has no industry and academic affiliations and is an) s
5 335 M
( independent academic and professional\) alone after 2011, significantly expanding previous ) s
5 324 M
(publications. They are subject to errors. This was because of some administrative and pract) s
5 313 M
(ical hurdles in obtaining faculty guidance from 2013 onwards while trying to resume PhD aft) s
5 302 M
(er a work tenure.) s
5 280 M
(**Is there a central theme connecting the publications, drafts and their implementations me) s
5 269 M
(ntioned previously?**) s
5 247 M
(Yes. All these drafts revolve around the fundamental philosophical/mathematical question - ) s
5 236 M
(Which choice is better? Group Social Choice by Majority or Any Choice function other than M) s
5 225 M
(ajority? Is it possible to determine merit intrinsically unpolluted by mass opinions? This ) s
5 214 M
(problem has been studied for centuries e.g Condorcet Jury Theorem. Drafts and publications ) s
5 203 M
(above are efforts in this direction translating this question to problems requiring measure) s
5 192 M
(ment of merit and ranking of text etc., in World Wide Web and Human Social Networks. These ) s
5 181 M
(drafts bridge the usual chasm between Theoretical Computer Science and Engineering side of ) s
5 170 M
(it like Machine Learning by concepts drawn from Boolean social choice, Pseudorandomness, Bo) s
5 159 M
(olean Satisfiability, Learning theory etc.,. Notion of Complementing a Function has origins) s
5 148 M
( in computability theory \(Hilbert's tenth problem, Solutions to Diophantine Equations, MRDP) s
5 137 M
( theorem etc.,\) and closely relates to Ramsey Theory of Coloring sequences of real/integer ) s
5 126 M
(lines. Complementation of a function is also another facet of social choice e.g Complement ) s
5 115 M
(of a social choice function - "Who voted in favour" is a complement of a social choice func) s
5 104 M
(tion - "Who did not vote in favour". In complexity parlance, complementation is reminiscent) s
5 93 M
( of the definition of C and Co-C complexity classes for some class C. Integer partition and) s
5 82 M
( Locality Sensitive Hashing are theoretical gadgets for a multipartisan voting - votes are ) s
5 71 M
(partitioned among candidates and each candidate has similar voters chained in an LSH bucket) s
5 60 M
( together. LSH Hash function of 2 buckets is nothing but the boolean majority function in t) s
5 49 M
(abulation and each bucket has a generating function which are mutually complement functions) s
5 38 M
(. Complement Functions are special subsets of Diophantine Equations in which two complement) s
5 27 M
(ary sets \(or sets in an exact cover\) are defined by Diophantine Equations. Integer Factoriz) s
5 16 M
(ation is also a diophantine problem e.g. Brahmagupta's Chakravala and Solutions to Pell Equ) s
5 5 M
(ation etc., Integer Factorization is a peripheral requirement for integer partitioning - ea) s
_R
S
%%Page: (8) 8
%%BeginPageSetup
_S
18 36 translate
/pagenum 8 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (8) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(ch number can be partitioned in as many ways as sum of products of frequencies of partition) s
5 731 M
( and size of partition - defined by coefficients in partition generating function. Space fi) s
5 720 M
(lling/Circle filling algorithms are packing constraint satisfaction problems which can be s) s
5 709 M
(ocial choice functions too \(each packing problem is an objective function of a voter maximi) s
5 698 M
(zed by a candidate\). Complement Functions can be generalized to Diophantine Equations for s) s
5 687 M
(ets in exact cover and are thus special subproblems of Space filling/Packing/Tiling problem) s
5 676 M
(s \(e.g Pentominoes tiling exact cover of plane\). These drafts describe a parallel PRG cellu) s
5 665 M
(lar automaton algorithm for space filling. Last but not the least, Complement Function gene) s
5 654 M
(ralizes the well-known patterns in primes problem \(which is related to real part of non-tri) s
5 643 M
(vial zeros of Riemann Zeta Function\) - a function complementing integer factorization impli) s
5 632 M
(es pattern in primes. Prime-Composite complementation is also related to Jones-Sato-Wada-Wi) s
5 621 M
(ens Theorem - http://www.math.ualberta.ca/~wiens/home%20page/pubs/diophantine.pdf - set of ) s
5 610 M
(primes is exactly the set of values of a polynomial in 25 degree - 26 variables - because p) s
5 599 M
(rimes are recursively enumerable Diophantine set. Pattern in primes is also a problem relat) s
5 588 M
(ed to energy levels of Erbium nuclei - Freeman Dyson and Montgomery statistics - http://see) s
5 577 M
(dmagazine.com/content/article/prime_numbers_get_hitched/ . Intrinsic merit versus perceived) s
5 566 M
( merit dichotomy has immense complexity theoretic ramifications which are analyzed in the d) s
5 555 M
(rafts which have to be read with the caveat: equating majority and non-majority social choi) s
5 544 M
(ces subsume all classes of complexity zoo under equal goodness \(in the context of Condorcet) s
5 533 M
( Jury Theorem Group Decision vis-a-vis a non-conventional social choice\) and completeness a) s
5 522 M
(ssumptions. Intrinsic merit is about objectively determining value of an entity \(text, acad) s
5 511 M
(emic papers, audio-visuals and humans too\) whereas Condorcet Jury Theorem and its later enh) s
5 500 M
(ancements are about correctness of subjective Majority Voting Decision. Notion of Intrinsic) s
5 489 M
( Merit already has been widely studied in the name of Intrinsic Fitness of a vertex in Soci) s
5 478 M
(al Networks \(ability to attract links\) - e.g Bianconi-Barabasi Network Bose-Einstein Fitnes) s
5 467 M
(s and its later derivative papers. Previous publications till 2010 devote only to intrinsic) s
5 456 M
( merit of text documents and later draft expansions after 2011 generalize it to merit of an) s
5 445 M
(y\(text, audio, visuals, people\). Most of the literature assumes a probability distribution ) s
5 434 M
(of fitness/merit and not finding it. These drafts are efforts in this direction to pinpoint) s
5 423 M
( how to quantize intrinsic fitness/merit. Obviously defining intrinsic merit is a difficult) s
5 412 M
( problem, but there are precedents to solving it e.g individual social merit is measured by) s
5 401 M
( examinations/question-answering/contests etc., not much by voting. Both these problems red) s
5 390 M
(uce to satisfying a boolean formula \(e.g 3SAT\) of arbitrary complexity class because "judgi) s
5 379 M
(ng" implies extent of constraints satisfied e.g Voters have varied 3CNFs to rank a candidat) s
5 368 M
(e making it subjective while Intrinsic merit requires an absolute 3CNF. Finding an absolute) s
5 357 M
( CNF is the leitmotif of all Intrinsic Merit algorithms implemented in NeuronRain - this is) s
5 346 M
( computational learning theory problem viz.,PAC Learning, MB Learning etc., All Deep Learni) s
5 335 M
(ng algorithms including BackPropagation, Convolution, Recurrent Neural Networks etc., learn) s
5 324 M
( from errors and iteratively minimize. Neural networks are theoretically equivalent to thre) s
5 313 M
(shold AC=NC=TC circuits. Learning theory goes beyond just constructing formulas and places ) s
5 302 M
(limits on what is efficiently learnable. Merit computed by these can be translated to varia) s
5 291 M
(bles in a CNF. NeuronRain implements a Least Square Approximate MaxSAT solver to rank the t) s
5 280 M
(argets by the percentage of clauses satisfied.) s
5 258 M
(Following are the conceptual relations between various draft publications in a nutshell cre) s
5 247 M
(ating a connected graph:) s
5 236 M
(        1. Intrinsic Merit is a Non-majority Social Choice Function and quantifies merit of) s
5 225 M
( text, audio/music, visuals and people. Intrinsic merit is omnipresent - wherever rankings ) s
5 214 M
(are required intrinsic merit finds place vis-a-vis perceptive/fame rankings. 9 classes of m) s
5 203 M
(erit have been defined in the drafts and implemented:) s
5 192 M
(           1.1 text\(recursive gloss overlap,recursive lambda function growth,Question-Answe) s
5 181 M
(ring\), ) s
5 170 M
(           1.2 audio-speech\(recursive lambda function growth\), ) s
5 159 M
(           1.3 audio-music\(mel frequency cepstral coefficients,weighted automata\), ) s
5 148 M
(           1.4 visuals-images\(ImageGraph\), ) s
5 137 M
(           1.5 visuals-videos\(VideoGraph EventNet Tensor products\), ) s
5 126 M
(           1.6 people-experiential and intrinsic\(recursive mistake correction tree, Questio) s
5 115 M
(n-Answering in Interviews/Examinations/Contests\), ) s
5 104 M
(           1.7 people-lognormal least energy\(inverse lognormal sum of education-wealth-valo) s
5 93 M
(ur\), ) s
5 82 M
(           1.8 people-attrition\(tenure histogram set partitions - correlations, set partiti) s
5 71 M
(on analytics\), ) s
5 60 M
(           1.9 economic merit of nations\(logistic regression, Gravity model in economic net) s
5 49 M
(works\).) s
5 38 M
(        2. Complement Functions are subset of Diophantine Equations \(e.g Beatty functions\).) s
5 27 M
( Polynomial Reconstruction Problem/List decoding/Interpolation which retrieve a polynomial ) s
5 16 M
(\(exact or approximate\) for set of message points is indeed a Diophantine Representation/Dio) s
5 5 M
(phantine Approximation problem for the complementary sets \(e.g. approximating Real Pi by Ra) s
_R
S
%%Page: (9) 9
%%BeginPageSetup
_S
18 36 translate
/pagenum 9 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (9) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(tional Continued Fractions\). Undecidability of Complement Diophantine Representation follow) s
5 731 M
(s from MRDP theorem and Post's Correspondence Problem.) s
5 720 M
(        3. Factorization has a Diophantine Representation \(Pell Equation\)) s
5 709 M
(        4. Tiling/Filling/Packing is a generalization of Complement Functions \(Exact Cover\)) s
5 698 M
(.) s
5 687 M
(        5. Majority Function has a Tabulation Hashing definition \(e.g Electronic Voting Mac) s
5 676 M
(hines\) i.e Hash table of candidates as keys and votes per candidate as chained buckets ) s
5 665 M
(        6. Integer Partitions and Tabulation Hashing are isomorphic e.g partition of an int) s
5 654 M
(eger 21 as 5+2+3+4+5+2 and Hash table of 21 values partitioned by keys on bucket chains of ) s
5 643 M
(sizes 5,2,3,4,5,2 are bijective. Both Set Partitons and Hash tables are exact covers quanti) s
5 632 M
(fied by Bell Numbers/Stirling Numbers. Partitions/Hashing is a special case of Multiple Age) s
5 621 M
(nt Resource Allocation problem. Thus hash tables and partitions create complementary sets d) s
5 610 M
(efined by Diophantine equations.) s
5 599 M
(        7. Ramsey Coloring and Complementation are equivalent. Ramsey coloring and Compleme) s
5 588 M
(nt Diophantines can quantify intrinsic merit of texts) s
5 577 M
(        8. Graph representation of Texts and Lambda Function Composition are Formal Languag) s
5 566 M
(e and Algorithmic Graph Theory Models e.g parenthesization of a sentence creates a Lambda F) s
5 555 M
(unction Composition Tree of Part-of-Speech.) s
5 544 M
(        9. Majority Function - Voter SAT is a Boolean Function Composition Problem and is r) s
5 533 M
(elated to an open problem - KRW conjecture - and hardness of this composition is related to) s
5 522 M
( another open problem - P Vs NP.) s
5 511 M
(        10. Majority Versus Non-Majority Social Choice comparison arises from Condorcet Jur) s
5 500 M
(y Theorem and Margulis-Russo Threshold phenomenon in Boolean Social Choice i.e how individu) s
5 489 M
(al decision correctness affects group decision correctness. Equating the two social choices) s
5 478 M
( has enormous implications for Complexity theory because all complexity classes are subsume) s
5 467 M
(d by Majority-VoterSAT boolean function composition.) s
5 456 M
(        11. Intrinsic Merit Ranking can be defined as a MAXSAT problem. Random matrix based) s
5 445 M
( LSMR/LSQR SAT solver  approximately solves MAXSAT in polynomial time on an average. Rankin) s
5 434 M
(g of texts based on distance similarity is also a problem solved by collision-supportive Lo) s
5 423 M
(cality Sensitive Hashing - similar texts are clustered in a bucket chain.) s
5 412 M
(        12. Question-Answering/Interview Intrinsic Merit is a QBFSAT problem. Question-Answ) s
5 401 M
(ering is also a Linear or Polynomial Threshold Function in Learning theory perspective) s
5 390 M
(        13. Pseudorandom Choice is a Non-Majority Social Choice Function) s
5 379 M
(        14. Voter SAT can be of any complexity class - 3SAT, QBFSAT etc.,) s
5 368 M
(        15. Space Filling by circles is a vast area of research - Circle Packing. Parallel ) s
5 357 M
(Circle Packing unifies three fields - Parallel Pseudorandom Generators \(ordinates on 2-D pl) s
5 346 M
(ane are generated in parallel and at random which is underneath most natural processes\), 0-) s
5 335 M
(1 Integer Linear Programming and Circle Packing. Efficient parallel circle packing has comp) s
5 324 M
(utational geometric importance - geometric search where each circle is a query which might ) s
5 313 M
(contain expected point - planar point location. Random Close Packing and Circle Packing are) s
5 302 M
( Constraint Satisfaction/SAT Problems.) s
5 291 M
(        16. Intrinsic Merit is the equivalent of Intrinsic Fitness in Social Networks and E) s
5 280 M
(xperiential learning is defined in terms of intrinsic merit and mistake bound learning. Rec) s
5 269 M
(ursive Lambda Function Growth Algorithm for creating lambda function composition trees from) s
5 258 M
( random walks of Definition Graphs of Text simulates Human Brain Connectomes. High Expander) s
5 247 M
( Definition Graphs are intrinsically better connected and meritorious because average links) s
5 236 M
( incident per vertex or sets of vertices is high from definition of Expander Graphs. This p) s
5 225 M
(arallels Bose-Einstein Condensation in Networks in which least energy nodes attract most li) s
5 214 M
(nks. An algorithm for EventNet and ImageNet Graph based Intrinsic Merit for Large Scale Vis) s
5 203 M
(uals and Audio has been described in AstroInfer Design Documents \(EventNet Tensor Products ) s
5 192 M
(Algorithm\) and has been implemented in AstroInfer for the hardest Video Merit - Large Scale) s
5 181 M
( Visual Recognition Challenge \(LSVR\).) s
5 170 M
(        17. Intrinsic Merit versus Perceived Merit and Non-Majority Versus Majority Social ) s
5 159 M
(Choice are equivalent - Absolute Versus Subjective - and can be defined in terms of Mechani) s
5 148 M
(sm Design/Flow Market Equilibrium in Algorithmic Economics. In Social Networks this is well) s
5 137 M
(-studied Fame Versus Merit Problem.) s
5 126 M
(        18. Money Changing Problem/Coin Problem/Combinatorial Schur Theorem for Partitions ) s
5 115 M
(and Tabulation Hashing are equivalent i.e expressing an integer as a linear combination of ) s
5 104 M
(products, which defines distribution of buckets in a hash table.) s
5 93 M
(        19. ThoughtNet/EventNet are theoretical reinforcement learning simulations of Cogni) s
5 82 M
(tive Evocation, Cause-Effect ordering and events involving actors in Clouds. ThoughtNet is ) s
5 71 M
(a contextual multiarmed bandit Hypergraph which evokes thought/knowledge of maximum potenti) s
5 60 M
(al. Potential of thoughts/knowledge in Hypergraph is proportional to their intrinsic merit.) s
5 49 M
( Name ThoughtNet is a misnomer because it focuses only on evocation and doesn't exactly ref) s
5 38 M
(lect human thought in its fullest power which is a far more complicated, less-understood op) s
5 27 M
(en problem. Name ThoughtNet was chosen to differentiate between another evocation framework) s
5 16 M
( - Evocation WordNet \(https://wordnet.princeton.edu/sites/wordnet/files/jbj-jeju-fellbaum.p) s
5 5 M
(df - "...assigned a value of \342\\200\\234evocation\342\\200\\235 representing how much the first co) s
_R
S
%%Page: (10) 10
%%BeginPageSetup
_S
18 36 translate
/pagenum 10 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (10) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(ncept brings to mind the second..."\)) s
5 731 M
(        20. Neuro Electronic Currency is an experimental fictitious currency for modelling ) s
5 720 M
(Intrinsic Merit in economic networks. EventNet is an economic network for Money Flow Market) s
5 709 M
(s/Trade. Intrinsic merit in economic network is the economic influence of each vertex in tr) s
5 698 M
(ade.) s
5 687 M
(        21. Text sentences are Ramsey colored by Part-of-Speech tags and alphabet positions) s
5 676 M
(. Similarly graph representation of texts are Ramsey edge-colored by relations \(e.g WordNet) s
5 665 M
(, ConceptNet relations\). Text-graph complement to convert cliques to independent sets and v) s
5 654 M
(ice-versa is a special application of Complement Functions. Coloring texts by vowel-consona) s
5 643 M
(nt and alphabets creates 2-coloring and 255 coloring respectively and imply existence of mo) s
5 632 M
(nochromatic APs in texts. Vowel-consonant 2-coloring and vowelless string complexity are eq) s
5 621 M
(uivalent to Compressed Sensing sketches i.e extracted APs are sketches compressing text.) s
5 610 M
(        22. Shell Turing Machines are experimental novelty in definition of Turing computab) s
5 599 M
(ility which introduce dimension of truth as an additional parameter in addition to tapes, a) s
5 588 M
(lphabets, head of tape etc., to simulate hierarchy of truths across dimensions E.g 2-D Turi) s
5 577 M
(ng Machine has no knowledge about concept of Volume which is defined only in a 3-D Turing M) s
5 566 M
(achine. This has similarities to Tarski Truth Undefinability - Object language versus Meta ) s
5 555 M
(Language and parallels Goedel Incompleteness. Shell Turing machines have applications in in) s
5 544 M
(trinsic merit definitions in the context of word2vec embeddings of words in vector spaces. ) s
5 533 M
(Colloquial example: Two Turing machines computing name of "Tallest building" on two vector ) s
5 522 M
(spaces \(or universe of discourses in First Order Logic\) of different dimensions - "Country") s
5 511 M
( and "World" - Country is a subspace of World - might return two different results though q) s
5 500 M
(uestion is same. Formally, Shell Turing Machines have parallels to Turing Degrees which are) s
5 489 M
( measures of unsolvability of a set. Turing Degree is an equivalence class and two Turing m) s
5 478 M
(achines X and Y have degrees defined by partial order d\(X\) > d\(Y\) meaning X solves a more d) s
5 467 M
(ifficult set than Y. Essentially, Shell Turing machines defined over two vector spaces of t) s
5 456 M
(wo dimensions d1 > d2 can be construed as two machines of varying Turing degrees.Reduction ) s
5 445 M
(from Turing degrees to Dimensions of Shell Turing Machines: Shell Turing machines defined o) s
5 434 M
(n vector space of dimension d+x have oracle access to a shell Turing machine on vector spac) s
5 423 M
(e of dimension d creating a Turing jump. Hilbert Machines defined on Hilbert Spaces, Eilenb) s
5 412 M
(erg Linear Machines defined on vector spaces are examples of Shell Turing Machines - http:/) s
5 401 M
(/citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.73&rep=rep1&type=pdf - "...  The noti) s
5 390 M
(on of a linear machine goes back at least 25 years to Eilenberg [14]. The basic idea is to ) s
5 379 M
(base a machine \(or automata\) not just on a non-interpretable set of symbols but instead use) s
5 368 M
( a linear structure. That means, that the data this type of machines operates on are vector) s
5 357 M
(s in some vector space ..." , https://www.nap.edu/read/10169/chapter/9#107 - "...One of my ) s
5 346 M
(fonder memories comes from sitting next to Sammy in the early 1960s when Frank Adarns gave ) s
5 335 M
(one of his first lectures on how every functor on finite-dimensional vector spaces gives ri) s
5 324 M
(se to a natural transformation on the K-functor...") s
5 313 M
(        23. Pseudorandomness and Random Close Packing are equivalent - a random close packi) s
5 302 M
(ng is generated by a pseudorandom generator e.g shaking a container of balls shuffles the c) s
5 291 M
(entroids of balls at random. Cellular Automaton algorithm uses Parallel PRGs to simulate Fi) s
5 280 M
(lling of Space by random strewing of solids/liquids.) s
5 269 M
(        24. A random integer partition can be generated by a Pseudorandom generator. This e) s
5 258 M
(xtends the Partition-HashTable isomorphism to PRG-Partition-Hashtable transitive equivalenc) s
5 247 M
(e: PRG produces random partitions of integer, random partitions map to random buckets in ta) s
5 236 M
(bulation hashing. ) s
5 225 M
(        25. Computational Geometric Parallel RAM Factorization applies datastructures \(e.g ) s
5 214 M
(Parallel construction of segment trees/wavelet trees\) and algorithms \(Planar Point Location) s
5 203 M
(, ray shooting queries\) from Computational Geometry and Number Theory. Factorization in num) s
5 192 M
(ber theory is a multiplicative partition problem - Factorisatio Numerorum - as opposed to a) s
5 181 M
(dditive partitions. Quantum Computational version of Computational Geometric factorization ) s
5 170 M
(has also been described in the context of quantum to classical decoherence.) s
5 159 M
(        26. Program Analysis is a converse of complement diophantine problem and is an appr) s
5 148 M
(oximation of Rice Theorem which ordains any non-trivial property of recursively enumerable ) s
5 137 M
(sets is Undecidable.) s
5 126 M
(        27. Software Analytics based on static and dynamic analyses \(SATURN CFG/Valgrind Ca) s
5 115 M
(llGraphs/Points-to Graphs\) and applying Graph Mining/Latent Semantic Indexing on them is a ) s
5 104 M
(Program Analysis problem.) s
5 93 M
(        28. Set Partitions \(Complementary Sets, LSH Partitions, Separate Chaining Hash tabl) s
5 82 M
(es, Histograms etc.,\) have a reduction to Space Filling/Packing by Exact Square Tile Cover ) s
5 71 M
(of Rectangle from a fundamental result in number theory - Lagrange Four Square Theorem. Thi) s
5 60 M
(s kind of square tile cover of a rectangle can be written as a non-linear programming optim) s
5 49 M
(ization which solves integer factorization indirectly.) s
5 38 M
(        29. Computational Geometric Factorization by Parallel Planar Point Location rectifi) s
5 27 M
(es a hyperbolic continuous curve to set of straightline segments as part of factorization w) s
5 16 M
(hich are searched. Each rectified segment is an arithmetic progression defineable by an ari) s
5 5 M
(thmetic progression diophantine and set of these diophantines represent the exact cover \(se) s
_R
S
%%Page: (11) 11
%%BeginPageSetup
_S
18 36 translate
/pagenum 11 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (11) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(t of subsets\) of points on rectified hyperbolic curve. Arithmetic progressions arise in Ram) s
5 731 M
(sey theory while arbitrarily coloring integer sequences.) s
5 720 M
(        30. Question-Answering Interview Intrinsic Merit as a threshold function \(linear or) s
5 709 M
( polynomial\) is related to an open problem in boolean functions - BKS conjecture. BKS conje) s
5 698 M
(cture predicts existence of a function which is more resilient or stabler than majority fun) s
5 687 M
(ction. Stability is a measure of incorruptibility of a function.) s
5 676 M
(        31. Category Theory is the most fundamental abstraction of mathematics. Morphisms a) s
5 665 M
(nd Functors of Categories on algebraic topological spaces can be formulated as Shell Turing) s
5 654 M
( Machines on some topological space defined on objects embedded in topological space.) s
5 643 M
(        32. EventNet Logical Clock which has been applied for EventNet Tensor Products meri) s
5 632 M
(t of Large Scale Visuals can be formalised by Category Theory - as Event Categories and Mor) s
5 621 M
(phisms amongst Actors with in an Event and Causation Functors across Events.) s
5 610 M
(        33. Shell Turing Machines have connections to Diophantine Equations - set of langua) s
5 599 M
(ges of all Shell Turing Machines cover the set of Recursively Enumerable languages and MRDP) s
5 588 M
( theorem equates Diophantine Equations and Recursively Enumerable sets. Relation between di) s
5 577 M
(mension of topological space of a Shell Turing Machine and \(degree, number of unknowns\) of ) s
5 566 M
(its Diophantine representation is an open problem) s
5 544 M
(**Why is Intrinsic Merit necessary? Are there counterexamples to perceptive voting based ra) s
5 533 M
(nking? Why is voting based merit judgement anachronistic?**) s
5 511 M
(Following counterexamples on merit-fame\(prestige\) anachronism and Q&A already mentioned in ) s
5 500 M
(AstroInfer Design Document are quoted herewith as they are pertinent to this question:) s
5 489 M
(*\) Performance of an academic personality is measured first by accolades,awards,grades etc.) s
5 478 M
(, which form the societal opinion - prestige \(citations\). That is prestige is created from ) s
5 467 M
(intrinsic merit. But measuring merit from prestige is anachronistic because merit precedes ) s
5 456 M
(prestige. Ideally prestige and intrinsic merit should coincide when the algorithms are equa) s
5 445 M
(lly error-free. In case of error, prestige and merit are two intersecting worlds where docu) s
5 434 M
(ments without merit might have prestige and vice-versa. Size of the set-difference is measu) s
5 423 M
(re of error.  *\) Soccer player, Cricket player or a Tennis player is measured intrinsically) s
5 412 M
( by number of goals scored, number of runs/wickets or number of grandslams won respectively) s
5 401 M
( and not subjectively by extent of votes or fan following to them \(incoming edges\). Here re) s
5 390 M
(ality and perception coincide often and an intrinsically best player by records is also mos) s
5 379 M
(t revered. Any deviation is because of human prejudice. Here intrinsic merit precedes socia) s
5 368 M
(l prestige.  *\) Merits of students are judged by examinations \(question-answering\) and not ) s
5 357 M
(by majority voting by faculty. Thus question-answering or interview is an algorithm to meas) s
5 346 M
(ure intrinsic merit objectively. Here again best student in terms of marks or grades is als) s
5 335 M
(o the most favoured. Any deviation is human prejudice. Interview of a document is how relev) s
5 324 M
(ant it is to a query measured by graph edit distance between recursive gloss overlap graphs) s
5 313 M
( of query and text. Here also intrinsic merit precedes social prestige. Caveat is these exa) s
5 302 M
(mples do not prove voting is redundant but only exemplify that Voting succeeds only when al) s
5 291 M
(l voters decide merit with high degree of accuracy \(Condorcet Jury Theorem\). *\) Legal Syste) s
5 280 M
(m rests on this absoluteness - People frame law, reach consensus on its clauses and Everyon) s
5 269 M
(e agrees and accepts Law as a standard. *\) Most obvious counterexample to perceptive rankin) s
5 258 M
(g is the pricing in money flow markets. Same Good and Service is differentially priced by d) s
5 247 M
(ifferent Sellers. Widely studied question in algorithmic economics is how to fix an absolut) s
5 236 M
(e price for commodity. There are only equilibrium convex program solutions available \(Nash,) s
5 225 M
(Fisher,Eisenberg-Gale\) where buyer-seller may reach an agreement point which is not necessa) s
5 214 M
(rily intrinsic. This problem is parallel to existence of Intrinsic Merit/Fitness in world w) s
5 203 M
(ide web and social networks. *\) Stock buy-sell decisions are often influenced by Credit Rat) s
5 192 M
(ing agencies which is also an intrinsic merit assessment in financial markets. *\) Darwin's ) s
5 181 M
(Theory of Natural Selection and Survival of the Fittest is one of the oldest scientific exa) s
5 170 M
(mple for Intrinsic merit or fitness in anthropology - Nature makes beings to compete with e) s
5 159 M
(ach other for survival, less fit become extinct and the fittest of them emerge victorious a) s
5 148 M
(nd evolve. *\) Economic Networks for Shock Propagation\(https://economics.mit.edu/files/9790\)) s
5 137 M
( - Gravity Model of Economic Networks and GDP as intrinsic fitness measure in World Trade W) s
5 126 M
(eb - https://www.nature.com/articles/srep15758 and https://arxiv.org/pdf/1409.6649.pdf \(A G) s
5 115 M
(DP-driven model for the binary and weighted structure of the International Trade Network\) *) s
5 104 M
(\) Human Development Index Rankings of Countries which is a geometric mean of Life Expectanc) s
5 93 M
(y Index, Education Index and Income Index - http://hdr.undp.org/sites/default/files/hdr_201) s
5 82 M
(3_en_technotes.pdf - is an intrinsic macroeconomics merit measure. ) s
5 71 M
( ) s
5 60 M
(**Why should intrinsic merit be judged only by mapping a text to a graph?** ) s
5 38 M
(This is not the only possible objective intrinsic merit judgement. There could be other way) s
5 27 M
(s too. Disclaimer is intrinsic merit assumes cerebral representation of sensory reception \() s
5 16 M
(words, texts, visuals, voices etc.,\) and its complexity to be the closest to ideal judgemen) s
5 5 M
(t. Simulating cerebral representation of meaning by a neural network therefore approximates) s
_R
S
%%Page: (12) 12
%%BeginPageSetup
_S
18 36 translate
/pagenum 12 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (12) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
( intrinsic merit well \(BRAIN initiative - circuit diagram of neurons - http://www.braininit) s
5 731 M
(iative.org/achievements/making-the-connection/ - neurons for similar tasks are closely conn) s
5 720 M
(ected\). Usually cognition of text or audio-visuals, can be approximated by bottom-up recurs) s
5 709 M
(ive lambda function composition tree evaluation on each random walk of the Definition Graph) s
5 698 M
(. Graph representation of a text can be easily made into a Graph Neural Network, a recent a) s
5 687 M
(dvance in Deep Learning, and thus closely resembles internal neural synaptic activation in ) s
5 676 M
(brain on reading a text. AstroInfer implements this as Graph Neuron Tensor Network \(GNTN\) o) s
5 665 M
(n lambda composition tree of random walks on definition graph which is a merger of Graph Ne) s
5 654 M
(ural Networks\(GNN\) and Neural Tensor Network\(NTN\). Neural Tensor Networks formalize similar) s
5 643 M
(ity of two vertices connected by a relation as a Tensor Neuron and are ideally suitable for) s
5 632 M
( ontologies like WordNet. Intrinsic Merit can also have errors similar to Perceptive Majori) s
5 621 M
(ty Vote Ranking. But Intrinsic Merit has an inherent cost advantage compared to aggregating) s
5 610 M
( votes. ) s
5 588 M
(Intrinsic Merit in the context of psychology has its origins in various types of cognition ) s
5 577 M
(- Grounded Cognition, Embodied Cognition etc., - Embodied Cognition puts forth revolutionar) s
5 566 M
(y concept of "body influencing mind and cognition is not limited to cerebral cortices" whil) s
5 555 M
(e Grounded cognition defines how language is understood. Following excerpts from psychology) s
5 544 M
( literature illustrate cognition:) s
5 533 M
(        *\) Barsalou's Grounded Cognition - https://www.slideshare.net/jeannan/on-barsalous-) s
5 522 M
(grounded-cognition) s
5 511 M
(        *\) Grounded Cognition - http://matt.colorado.edu/teaching/highcog/readings/b8.pdf -) s
5 500 M
( 1\) "...Phrasal structures embed recursively.\(e.g The dog the cat chased howled\). Propositi) s
5 489 M
(ons extracted from linguistic utterances represent meaning beyond surface structure.e.g ext) s
5 478 M
(racting chase\(cat,dog\) from either "The cat chased the dog" or "The dog was chased by the c) s
5 467 M
(at"..." 2\) "...as an experience occurs \(e.g easing into a chair\) brain captures states acro) s
5 456 M
(ss modalities and integrates them with a multimodal representation stored in memory \(e.g ho) s
5 445 M
(w a chair looks and feels,the action of sitting,introspections of comfort and relaxations\).) s
5 434 M
( Later on when knowledge is needed to represent a category \(e.g chair\) multimodal represent) s
5 423 M
(ations captured during experiences are reactivated to simulate how brain represented percep) s
5 412 M
(tion, action and introspection associated with it ...") s
5 401 M
(        *\) Embodied Cognition - https://blogs.scientificamerican.com/guest-blog/a-brief-gui) s
5 390 M
(de-to-embodied-cognition-why-you-are-not-your-brain/) s
5 368 M
(ThoughtNet and Recursive Lambda Function Growth algorithms in NeuronRain exactly implement ) s
5 357 M
(previous grounded cognition theory - Language sentences are parsed into a recursive tree of) s
5 346 M
( lambda function compositions and each lambda function subtree composition can be simulated) s
5 335 M
( by composing images from a semantic network e.g ImageNet for approximate movie representat) s
5 324 M
(ion of meaning. ThoughtNet Hypergraph vertices are categories \(modalities or classes\) and e) s
5 313 M
(ach thought/sentence/experience is pigeonholed to classes \(or modalities by a classifier\). ) s
5 302 M
(Previous example experience "easing into a chair" can be a hyperedge sprawling the modal cl) s
5 291 M
(asses "comfort","chair","sitting" which are ThoughtNet hypervertices for modals. Any future) s
5 280 M
( experience of chair or sitting might evoke this experience based on its merit potential by) s
5 269 M
( Contextual Multi Armed Bandit.) s
5 247 M
(**Wouldn't cerebral representation vary from person to person and thus be subjective?**) s
5 225 M
(There are standardized event related potential \(ERP\) datasets \(N400,LAN,P600 etc., - https:) s
5 214 M
(//www.ncbi.nlm.nih.gov/pmc/articles/PMC3822000/\) and Event Related Functional MRI datasets ) s
5 203 M
(gathered from multiple neuroscience experiments on human subjects. Such ERP data are simila) s
5 192 M
(r for most brains. Variation in potential occurs because cerebral cortex and its sulci&gyri) s
5 181 M
( vary from person to person. It has been found that cortex and complexity of gray matter de) s
5 170 M
(termine intelligence and grasping ability. Intrinsic merit should therefore be based on bes) s
5 159 M
(t brain potential data. ERP is non invasive compared to fMRI. An example of how ERP related) s
5 148 M
( to "meaningfulness"/"semantic correctness" of two texts - meaningful and meaningless - is ) s
5 137 M
(plotted in https://brainlang.georgetown.edu/research/erplab. ) s
5 115 M
(**Isn't perception based ranking enough? Why is such an intrusive objective merit required?) s
5 104 M
(**) s
5 82 M
(Perception majority voting based ranking is accurate only if  all voters have decision corr) s
5 71 M
(ectness probability > 0.5 from Condorcet Jury Theorem. PageRank works well in most cases be) s
5 60 M
(cause incoming edges vote mostly with >50% correctness. This correctness is accumulated by ) s
5 49 M
(a Markov Chain Random Walk recursively - vote from a good vertex to another vertex implies ) s
5 38 M
(voted vertex is good \(Bonacich Power Centrality\) and so on. Initial goodness is based on we) s
5 27 M
(ight of an edge. Markov iteration stabilizes the goodness. Probability that goodness of sta) s
5 16 M
(tionary Markov distribution < 0.5 can be obtained by a tail bound and should be exponential) s
5 5 M
(ly meagre.) s
_R
S
%%Page: (13) 13
%%BeginPageSetup
_S
18 36 translate
/pagenum 13 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (13) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 731 M
(**Can Intrinsic Merit for a human social network vertex, a text document or any other entit) s
5 720 M
(y be precisely defined as opposed to a probability distribution for Intrinsic Fitness defin) s
5 709 M
(ed for Social network vertices?**) s
5 687 M
(Literature on Social network intrinsic fitness does not define but only relates why prefere) s
5 676 M
(ntial attachment happens in networks i.e Why certain social people profiles are highly rega) s
5 665 M
(rded and attract audience. Earlier Scale-Free networks defined degree of vertex exponential) s
5 654 M
(ly \(Power Law\) which is Rich-Get-Richer in random graphs \(Erdos-Renyi model\) i.e if a verte) s
5 643 M
(x has huge degree already it would have greater ability to attract future links. Recent adv) s
5 632 M
(ances place more importance on Fit-Get-Richer idiom and express fitness as a function of de) s
5 621 M
(gree \(a posteriori estimation\). Defining Exact Fitness is a void in literature still and In) s
5 610 M
(trinsic merit algorithms for texts fit in right there. These algorithms are not probabilist) s
5 599 M
(ic. For humans, defining merit independent of perception has a long drawn tradition - talk ) s
5 588 M
(to h\(im/er\) directly and judge and don't rely on popular opinions. This requires a consensu) s
5 577 M
(s on who judges merit and how. Previous counterexamples assume that such an Intrinsic, Abso) s
5 566 M
(lute standard exists e.g Examination/Interviews/Contests/Law are accepted standards to asse) s
5 555 M
(ss human merit - All students are asked same questions, All candidates are asked same quest) s
5 544 M
(ions, All contestants have equal levelled opportunities, All plaintiffs have equal freedom ) s
5 533 M
(to defend - Thus proving/disproving existence of absolute consensus standard is tantamount ) s
5 522 M
(to proving/disproving human intrinsic merit. Ultimately, intrinsic merit existence reduces ) s
5 511 M
(to consensus problem to measure merit - when everyone agrees on how to decide merit, percep) s
5 500 M
(tion gives way to intrinsic.) s
5 478 M
(**Aren't there counterexamples to Intrinsic Merit examples mentioned previously? For exampl) s
5 467 M
(e, aren't there brilliant scientists faring poorly in examinations? Aren't there bright can) s
5 456 M
(didates rejected by Interviews? And vice-versa? How do you explain it?**) s
5 434 M
(Probably this is the best question of this FAQ. These counterexamples imply the examination) s
5 423 M
(/interview system is flawed and violates consensus. Accuracy of Question-Answer based merit) s
5 412 M
( judgement depends on how efficiently the system samples merit from past history of the sub) s
5 401 M
(ject. This can be equivalently stated as Merit Summarization Problem \(similar to text summa) s
5 390 M
(rization\). If merit features are represented on a metric vector space, sampling should cons) s
5 379 M
(truct an efficient summary subspace of merit metric space. Clustering/Partitioning this spa) s
5 368 M
(ce by a computational geometric algorithm e.g Voronoi tessellation, Delaunay triangulation ) s
5 357 M
(etc., or a Clustering algorithm yields strong regions of merit. Question-Answeing should th) s
5 346 M
(erefore concentrate on these merit clusters. If points in this merit space are connected as) s
5 335 M
( a dependency graph, strongly connected components of the graph are closely related regions) s
5 324 M
( of merit and a component graph is the merit summary in which each vertex is a strongly con) s
5 313 M
(nected component. Theoretically, question answering reduces to a polynomial round QBFSAT an) s
5 302 M
(d is a PSPACE problem \(unbounded QBFSAT is EXP-complete\). Traditional question-answering is) s
5 291 M
( time-bounded and intrinsic merit need not depend on time restrictions - answering a questi) s
5 280 M
(on depends on how much instantaneous insight or epiphany a person has within limited time i) s
5 269 M
(n responding. This insight depends on both natural merit and past learning. It is against d) s
5 258 M
(efinition of merit itself because merit is absolute and independent of time while only expe) s
5 247 M
(riential learning grows over time. Problem therefore is how efficient and time-independent ) s
5 236 M
(the QBF is and this error in QBF is the failure probability of Intrinsic Merit. Probably ab) s
5 225 M
(ove counterexamples could have succeeded in unbounded, better-formed QBF. A nice academic e) s
5 214 M
(xample of unboundedness: Graduate/Doctoral studies give more importance to assignments, qui) s
5 203 M
(zzes, take-home exams in deciding course credit and merit which are less time-bounded compa) s
5 192 M
(red to conventional 3 hour tests. Someone failing in a 3 hour test might succeed in \(3+x\)th) s
5 181 M
( hour and time limit shouldn't constrain someone from proving their innate ability. But tra) s
5 170 M
(ditionally intelligence is measured by how fast a person solves a problem e.g puzzles and t) s
5 159 M
(his is based on assumption that all contestants have similar cerebral activity simultaneous) s
5 148 M
(ly in the duration of contest. This assumption is questionable - if problem solving faculty) s
5 137 M
( \(periods of peak creativity or insight\) of brain is plotted as a curve against time for ea) s
5 126 M
(ch individual, it is not necessary that curves of any two individuals should coincide. One ) s
5 115 M
(person might have peak cerebral activity/insight at time t \(during the contest\) and another) s
5 104 M
( might have peak activity/insight at t+dt \(outside the duration of contest\) and thus the in) s
5 93 M
(telligence quotient test fails to capture the merit of the latter. But the question of if p) s
5 82 M
(ast merit history can be efficiently constructed and sampled is itself non-trivial. Because) s
5 71 M
( this implies personalization in deciding merit. For instance, academic and work credential) s
5 60 M
(s in a curriculum vitae/resume has to be mapped to a graph or merit vector. Even if merit c) s
5 49 M
(lusters are conceivable, aforementioned limitation because of peak cerebral activity has to) s
5 38 M
( be accounted for accurate definition of intrinsic merit.) s
5 16 M
(**How measurable are Intrinsic merit and Creativity? Is there any perfect metric to quantif) s
5 5 M
(y these?**) s
_R
S
%%Page: (14) 14
%%BeginPageSetup
_S
18 36 translate
/pagenum 14 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (14) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 731 M
(There are metrics but not necessarily perfect. This requires a detailed anecdotal clarifica) s
5 720 M
(tion. Consider for example two sentences: "You saved the nation" and "You shaved the nation) s
5 709 M
(". Both are grammatically correct but latter is semantically discordant. First sentence is ) s
5 698 M
(obviously more meaningful because WordNet distance between "save" and "nation" is less than) s
5 687 M
( "shave" and "nation". Representing these sentences as a lambda function yields 2 functions) s
5 676 M
(: save\(nation\) and shave\(nation\) i.e verb acts as a function on the object. Best natural la) s
5 665 M
(nguage closer to realising lambda function composition without significant loss of informat) s
5 654 M
(ion is Sanskrit which has peculiar grammatical structure and brevity. An example sanskrit s) s
5 643 M
(entence below can be arbitrarily shuffled without loss of meaning \(Reference: Conversationa) s
5 632 M
(l Sanskrit - Cycle 35 - by N.D.Krishnamurthy, U.P.Upadhyaya, Jayanthi Manohar, N.Shailaja\):) s
5 621 M
(        api asmin maargae vaahanam na sthaapayitavyam ? - Are vehicular parkings prohibited) s
5 610 M
( in this road?) s
5 599 M
(is equivalent to:) s
5 588 M
(        asmin maargae na sthaapayitavyam vaahanam api ? ) s
5 577 M
(Lambda composition tree of this sentence might look like:) s
5 566 M
(        api\(asmin\(maargae\(na\(sthaapayitavyam\(vaahanam\)\)\)\)?) s
5 555 M
(where each parenthesis is a lambda function on an object argument and evaluated right-to-le) s
5 544 M
(ft. This lambda tree and wordnet relevance distance combine approximates quantitative compl) s
5 533 M
(exity of cerebral meaning representation well. Creativity or Genius has contextual interpre) s
5 522 M
(tations in academics/art/music/linguistics : Creativity in academics is measured by how inf) s
5 511 M
(luential a research paper is on future articles and how it is confirmed by experimental sci) s
5 500 M
(ence. For example, Einstein's papers on Special and General relativity grew in influence ov) s
5 489 M
(er the past 100 years because of its experimental validity \(Eddington Eclipse Experiment, G) s
5 478 M
(ravitational Lensing, Discovery of Black Holes, Precession of Equinox in Mercury's Orbit, G) s
5 467 M
(ravitational Waves found by CERN-LIGO etc.,\) and citations were the result of these experim) s
5 456 M
(ental proofs. Thus incoming hyperlinks or Fame is a result of Proved Intrinsic Merit \(or\) m) s
5 445 M
(erit in science is defined as experimental establishment of a theory and citations automati) s
5 434 M
(cally ensue. Creativity/Originality/Merit in art and music is far more complex to define e.) s
5 423 M
(g What made Mozart or Van Gogh famous? It is not known if there is an experimental proof fo) s
5 412 M
(r merit of music and art. But art and music are known to stimulate neural activity in human) s
5 401 M
(s and cure illness. Only an fMRI or an ERP dataset on these stimuli could quantify merit. F) s
5 390 M
(unctional MRI datasets for audio and music stimuli of different genres of music collected f) s
5 379 M
(rom human subjects are available in public domain at OpenfMRI - https://openfmri.org/datase) s
5 368 M
(t/ds000113b/, https://www.openfmri.org/dataset/ds000171/. These also contain respiratory an) s
5 357 M
(d heartbeat information on hearing music stimuli. There have been recent fMRI datasets like) s
5 346 M
( Human Connectome Project - https://www.humanconnectome.org/ - studying brain connectivity ) s
5 335 M
(and its relevance to Intelligence Quotient.) s
5 313 M
(**NeuronRain design documents and drafts refer to something called EventNet and ThoughtNet.) s
5 302 M
( What are they?**) s
5 280 M
(EventNet is a new protocol envisaged to picturise cause-effect relations in cloud. It is a ) s
5 269 M
(directed graph of event nodes each of which is an occurrence involving set of actors. This ) s
5 258 M
(can be contrasted against actors pattern in Akka\(http://doc.akka.io/docs/akka/current/scala) s
5 247 M
(/guide/actors-intro.html\) which has interacting actor objects. EventNet is graph of not jus) s
5 236 M
(t actors but events involving actors. ThoughtNet is another equivalent formalism to connect) s
5 225 M
( related concepts than events. This is a theoretically strengthened version of cognitive in) s
5 214 M
(ference model mentioned as uncommitted earlier in 2003. Basically ThoughtNet is a non-plana) s
5 203 M
(r Hypergraph of concepts. Each vertex in ThoughtNet is essentially a stack because multiple) s
5 192 M
( hyperedges go through a vertex and these edges can be imagined as stacked upon one another) s
5 181 M
(. Rough analogy is a source versioning system which maintains versions of code at multiple ) s
5 170 M
(time points. This model closely matches human evocative cognitive inference because upon se) s
5 159 M
(nsory perception of a stimulus, brain's associative  evocation finds all possible matching ) s
5 148 M
(thoughts and disambiguates them. Each set of evocations correspond to hyperedges transiting) s
5 137 M
( a stack vertex in ThoughtNet. ThoughtNet inherently has a temporal fingerprint because top) s
5 126 M
( most hyperedges of all stack vertices are the newest and deeper down the stack thoughts ge) s
5 115 M
(t older. Each hyperedge has a related potential and disambiguation depends on it. In machin) s
5 104 M
(e learning jargon, ThoughtNet is a Contextual Multi-Armed Bandit Reinforcement Learning Dat) s
5 93 M
(a Structure - an agent interacts with environment and its actions have rewards - each stack) s
5 82 M
( vertex is a multi-armed bandit environment and each element of the stack is an arm. Evocat) s
5 71 M
(ion scans the stack vertex to choose an arm followed by an action and most potent evocative) s
5 60 M
( thought fetches highest reward. Choice of a highest rewarding arm is the disambiguation an) s
5 49 M
(d depends on rewards for past evocation choices. Thus multi-armed bandit iteratively learns) s
5 38 M
( from past disambiguation to make future choices\(a generalization of hidden markov model wh) s
5 27 M
(ere present state depends on previous state\). This is a computational psychoanalytic framew) s
5 16 M
(ork and has some similarities to Turing machines/Pushdown automata with stack and tapes - b) s
5 5 M
(ut alphabet and languages are thoughts not just symbols. ThoughtNet can be simulated by a T) s
_R
S
%%Page: (15) 15
%%BeginPageSetup
_S
18 36 translate
/pagenum 15 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (15) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(uring Machine of hypergraph storage and computation state transition defined by evocative a) s
5 731 M
(ctions. Each actor in EventNet has a ThoughtNet. Thus EventNet and ThoughtNet together form) s
5 720 M
(alise causation, human evocation and action. New memories in human brain are acquired by Hi) s
5 709 M
(ppocampus and removal of Hippocampus causes difficulty in acquiring new memory though old m) s
5 698 M
(emories remain \(Reference: Limbic System and Hippocampus - Phantoms in Human Brain: Probing) s
5 687 M
( the mysteries of human mind - V.S.Ramachandran and Sandra Blakeslee\). Broca's Area in brai) s
5 676 M
(n processes Lexical-Grammatical aspects of sensory reception and forwards to Limbic System ) s
5 665 M
(for emotional reaction - https://www.ncbi.nlm.nih.gov/pubmed/19833971 by [Sahin NT1, Pinker) s
5 654 M
( S, Cash SS, Schomer D, Halgren E.] lists fMRI Local Field Potentials experimental observat) s
5 643 M
(ions for lexical-grammatical-phonological regular and irregular verb inflections \(200-320-4) s
5 632 M
(50ms\). ThoughtNet theoretically simulates Broca's Area, Hippocampus and Limbic system and a) s
5 621 M
(ccumulates memories on hypergraph. Word inflections are sourced and normalized from WordNet) s
5 610 M
( Synsets. Sensory Stimulus for example is a Galvanic Skin Response. Evocative action based ) s
5 599 M
(on stimulus by Limbic system is simulated by retrieval of the most potent thought hyperedge) s
5 588 M
( bandit arm and respectively defined action for the arm. NeuronRain grows ThoughtNet by cre) s
5 577 M
(ating vertex for each class of a thought hyperedge found by a classifier and storing the hy) s
5 566 M
(peredge across these class vertices. Example: Sentences "There is heavy flooding", "Typhoon) s
5 555 M
( wrought havoc","Weather is abnormal" are classified into 3 classes "Disaster","Water","Flo) s
5 544 M
(oding" found by a classifier. An example stimulus "Flooding" evokes all these sentences. Fo) s
5 533 M
(llowing diagrams explain it:) s
5 511 M
(.. image:: NeuronRain_ThoughtNet.jpg) s
5 489 M
(.. image:: NeuronRain_EventNet.jpg) s
5 467 M
( ) s
5 456 M
(**Why is a new Linux kernel required for cloud? There are Cloud operating systems already.*) s
5 445 M
(*) s
5 423 M
(Because, most commercial cloud operating systems are deployment oriented and cloud function) s
5 412 M
(ality is in application layer outside kernel. User has to write the boilerplate application) s
5 401 M
( layer RPC code. NeuronRain VIRGO provides system calls and kernel modules which obfuscate ) s
5 390 M
(and encapsulate the RPC code and inherent analytics ability within linux kernel itself. For) s
5 379 M
( example, virgo_clone\(\) , virgo_malloc\(\), virgo_open\(\) system calls transparently converse ) s
5 368 M
(with remote cloud nodes with no user knowledge, configured in virgo conf files - this featu) s
5 357 M
(re is unique in NeuronRain. Application developer \(Python/C/C++\) has to just invoke the sys) s
5 346 M
(tem call from userspace to embark on cloud. This is not possible in present linux distros. ) s
5 335 M
(Linux and unix system calls do not mostly use kernel sockets in system call kernelspace cod) s
5 324 M
(e and do not have kernel level support for cloud and analytics a void not compensated by ev) s
5 313 M
(en Cloud operating systems like openstack.) s
5 291 M
(**Fedora and Ubuntu Linux distros have optimized Linux Kernels for Cloud e.g linux-aws for ) s
5 280 M
(AWS. Is VIRGO Linux kernel similar to them?**) s
5 258 M
(No. Amazon Machine Image \(AMI\) for virtual machine hypervisors have optimized linux kernel ) s
5 247 M
(packages available for Fedora and Ubuntu. AWS has a network throughput enhancement named EN) s
5 236 M
(A \(Elastic Network Adapter\) which are device drivers \(https://github.com/amzn/amzn-drivers\)) s
5 225 M
( written to take advantage of Linux kernel Gigabit ethernet drivers. ENA has features for h) s
5 214 M
(ardware checksums of TCP packets, Multiple packet message queues, Packet Steering to a spec) s
5 203 M
(ific port etc.,. VIRGO Linux kernel does not presently do any ethernet optimization. But me) s
5 192 M
(ssage flags for kernel sockets send and receive between system call clients \(virgo_xxxxxx\(\)) s
5 181 M
( system calls in RPC/KMemCache/FileSystem\) and Kernel Module Listeners can be optimized by ) s
5 170 M
(having MSG_FASTOPEN to piggyback payload on SYN packets in SYN-ACK-SYNACK 3-way handshake. ) s
5 159 M
(MSG_FASTOPEN was experimented but it had to be reverted because of some random kernel panic) s
5 148 M
(s in kernel versions before 4.13.3. Presently MSG_FASTOPEN flag has been found to be workin) s
5 137 M
(g in kernel_analytics VIRGO64 module on 4.13.3 64-bit kernel for streaming analytics variab) s
5 126 M
(les realtime from a remote webservice. Fedora and Ubuntu AMIs leverage ENA for better respo) s
5 115 M
(nse time. Ubuntu press release at https://insights.ubuntu.com/2017/04/05/ubuntu-on-aws-gets) s
5 104 M
(-serious-performance-boost-with-aws-tuned-kernel/ details the enhancements. Notable among t) s
5 93 M
(hem is the CONFIG_NO_HZ_FULL Kconfig parameter which reduces scheduler clockticks. Clocksou) s
5 82 M
(rce is also a performance parameter - Changing to TSC clocksource improves CPU performance ) s
5 71 M
(\(NetFlix EC2 performance tuning for linux kernel - http://www.brendangregg.com/blog/2015-03) s
5 60 M
(-03/performance-tuning-linux-instances-on-ec2.html\). These are already available mainline c) s
5 49 M
(onfigurables and VIRGO kernel does not have anything new on that front. VIRGO kernel's main) s
5 38 M
( goal is to introduce new system calls and drivers for accessing resources/devices on remot) s
5 27 M
(e cloud nodes and all traffic happens only among kernelspaces of cloud nodes underneath use) s
5 16 M
(rspace applications - there are no userspace sockets.) s
_R
S
%%Page: (16) 16
%%BeginPageSetup
_S
18 36 translate
/pagenum 16 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (16) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(**What languages, libraries and third-party packages are used in NeuronRain?**) s
5 720 M
(AsFer machine learning implementations are written in C++/Python/Java\(Spark-streaming\). USB) s
5 709 M
(md VIRGO kernel module is written in C and Python\(Spark\). VIRGO linux kernel is forked off ) s
5 698 M
(from mainline http://www.kernel.org PPA and new systemcalls and drivers are written in C/Py) s
5 687 M
(thon\(Some utility scripts, Userspace boost::python invocation of systemcalls\). KingCobra VI) s
5 676 M
(RGO kernel module is written in C/Java/Python\(Pricing\)/C++\(protocol buffers for MAC electro) s
5 665 M
(nic currency\).) s
5 643 M
(Requirements.txt in:) s
5 632 M
(https://sourceforge.net/p/asfer/code/HEAD/tree/asfer-docs/Requirements.txt) s
5 621 M
(https://github.com/shrinivaasanka/asfer-github-code/blob/master/asfer-docs/Requirements.txt) s
5 610 M
(has continuously updated list of opensource packages/libraries dependencies - this file imp) s
5 599 M
(licitly attributes copyright/copyleft to respective original contributors.) s
5 577 M
(**How do VIRGO system calls and driver listeners differ from SunRPC?**) s
5 555 M
(SunRPC is one of the oldest ingredient of linux kernel making kernelspace TCP transport. Su) s
5 544 M
(nRPC is used by lot of distributed protocols e.g NFS. SunRPC kernel sockets code in http://) s
5 533 M
(elixir.free-electrons.com/linux/latest/source/net/sunrpc/svcsock.c is an example of how ker) s
5 522 M
(nelspace request-response happens. SunRPC is like a traditional ORB, requiring compilation ) s
5 511 M
(of stubs and implementations done in server side. Services register to portmap to get a ran) s
5 500 M
(dom port to run. Client discover the services via portmap and invoke remote functions. XML-) s
5 489 M
(RPC is a later advancement which uses XML encoded transport between client and server. XML-) s
5 478 M
(RPC is the ancestor of SOAP and present industry standard JSON-REST. Comparison of SunRPC a) s
5 467 M
(nd XML-RPC in http://people.redhat.com/rjones/secure_rpc/ shows how performant SunRPC is. S) s
5 456 M
(unRPC uses XDR for data representation.VIRGO presently does not have service registry, disc) s
5 445 M
(overy, stub generation like SunRPC because it delegates all those complexities to kernel an) s
5 434 M
(d user does not need to do any registration, service discovery or stub implementation. User) s
5 423 M
( just needs to know the unique name of the executable or function \(and arguments\) in the re) s
5 412 M
(mote cloud node. All cloud nodes must have replicated binaries which is the simplest regist) s
5 401 M
(ration. Ports are hardcoded and hence no discovery is required. Only linux 32-bit \(4.1.5\) a) s
5 390 M
(nd 64-bit \(4.13.3\) datatypes are supported. In this respect, VIRGO differs from any traditi) s
5 379 M
(onal RPC protocols. Marshalling/Unmarshalling have been ignored because, goal of VIRGO is n) s
5 368 M
(ot just RPC, but a logically unified kernel address-space and filesystems of all cloud node) s
5 357 M
(s - kernel address spaces of all cloud nodes are stored in a VIRGO address translation tabl) s
5 346 M
(e by VIRGO system calls. VIRGO system calls at present have a plain round-robin and a rando) s
5 335 M
(m-number based loadbalancing schemes. Research paper on userspace versus kernelspace remote) s
5 324 M
( procedure calls in http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.4304&rep=re) s
5 313 M
(p1&type=pdf has experimental results proving kernelspace RPC has a non-trivial speedup comp) s
5 302 M
(ared to userspace RPC in Amoeba OS. Most prominent cloud implementations \(JSON-RPC or JSON-) s
5 291 M
(REST\) do userspace RPCs presently and rarely use SunRPC-NFS style of kernelspace RPCs.Artic) s
5 280 M
(le in http://www.csn.ul.ie/~mark/fyp/fypfinal.html - CORBA in the kernel? - compares two me) s
5 269 M
(chanisms for kernelspace RPC - CORBA-kORBit and SunRPC. Quoting from it:"... One applicatio) s
5 258 M
(n of this is idea is that the user should be able to use a physical device attached to any ) s
5 247 M
(of the nodes in the cluster as if it were physically attached to the node the user was oper) s
5 236 M
(ating from. ...". VIRGO linux kernel systemcalls/drivers try to achieve exactly this where ) s
5 225 M
("physical device" is CPU, Kernel Memory and Filesystem in a remote cloud node. This is a ty) s
5 214 M
(pical feature required for a cloud of embedded systems. In this respect, VIRGO is a hybrid ) s
5 203 M
(of cloud and cluster for parallelism. VIRGO does not invoke SunRPC code at present and just) s
5 192 M
( derives the concept, though original intention was to wrap the system calls and drivers on) s
5 181 M
( SunRPC. Reason is the considerable code changes required in existing SunRPC socket code in) s
5 170 M
( kernel - thus VIRGO systemcalls and drivers were written from scratch.) s
5 148 M
(**Doesn't VIRGO expose the kernel address space directly to application user e.g Kernel Mem) s
5 137 M
(cache system calls?**) s
5 115 M
(VIRGO system calls, especially kmemcache virgo_malloc\(\)/virgo_get\(\)/virgo_set\(\)/virgo_free\() s
5 104 M
(\) system calls, allocate a contiguous kernel memory in a remote cloud node's kernel address) s
5 93 M
( space but refer to the memory locations only by VIRGO Unique ID which abstracts the user f) s
5 82 M
(rom kernel internals. Similarly, VIRGO cloudfs systemcalls virgo_open\(\), virgo_read\(\), virg) s
5 71 M
(o_write\(\), virgo_close\(\) read/write to a file in remote cloud node by VFS kernelspace funct) s
5 60 M
(ions. VIRGO Unique ID for a memory location is translated by the system call to actual kern) s
5 49 M
(el address in remote node which is not exposed to the user. As mentioned in earlier questio) s
5 38 M
(n of this FAQ on similarities to SunRPC/NFS/kORBit and elsewhere, VIRGO system calls try to) s
5 27 M
( unify kernel address spaces of all constituent nodes in the cluster/cloud mainly targeting) s
5 16 M
( IoT and embedded hardware. This requires mutual trust amongst the nodes of the cloud - e.g) s
5 5 M
( KTLS, OpenVPN Virtual IPs, Access Controlled Lists - which is presently a prerequisite and) s
_R
S
%%Page: (17) 17
%%BeginPageSetup
_S
18 36 translate
/pagenum 17 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (17) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
( KTLS is still in flux. Assuming availability of a secure trusted cloud, for example an off) s
5 731 M
(ice intranet having IoT devices in Servers, UPS, Lighting, Security CCTV cameras etc., whic) s
5 720 M
(h have their device memory addresses mmap\(\)-ed to kernel address space, VIRGO kmemcache and) s
5 709 M
( cloudfs system calls can directly access kernelspace address or storage of these devices w) s
5 698 M
(hich is permissible in trusted cloud. Presently this kind of IoT is done in userspace proto) s
5 687 M
(cols like MQTT/MAVlink. Most apt application of VIRGO system calls is the wireless cloud of) s
5 676 M
( drones/autonomous vehicles/fly-by-wire which require low latency - VIRGO system calls writ) s
5 665 M
(ing to kernelspace of remote vehicles in cloud for navigation/flight should theoretically b) s
5 654 M
(e faster than userspace protocols \(some research examples on AmoebaOS cited previously\) bec) s
5 643 M
(ause direct access to kernelspace bypasses lot of roundtrip of the packets from userspace t) s
5 632 M
(o kernelspace and viceversa. Motivation for KTLS was precisely to cut this overhead \(https:) s
5 621 M
(//netdevconf.org/1.2/papers/ktls.pdf - Figure 1 and 2 - send file implementation in kernels) s
5 610 M
(pace by Facebook bypassing userspace\). There have been some efforts to port memcached \(http) s
5 599 M
(://memcached.org/\) cacheing server to linux kernel - kmemcached in-kernel server - https://) s
5 588 M
(github.com/achivetta/kmemcached - which has similar motivation. ) s
5 566 M
(**Linux side of NeuronRain does everything in kernelspace transparent to userspace. Wouldn') s
5 555 M
(t this prohibit userspace cloud because end consumers are applications in userspace? Why sh) s
5 544 M
(ould transport be abstracted and submerged within kernel and re-emerge to userspace? Doesn') s
5 533 M
(t it affect response time?**) s
5 511 M
(End consumers are not necessarily only userspace applications. NeuronRain VIRGO systemcalls) s
5 500 M
(/driver listeners communicate in kernelspace which is prime necessity for embedded systems ) s
5 489 M
(cloud e.g cloud of devices like IoT. Thats why it has been reiterated NeuronRain is mainly ) s
5 478 M
(for kernelspace clouds and not for userspace which already has many frameworks. For example) s
5 467 M
(, KingCobra pub-sub depends on linux work-queue for enqueuing a message and servicing it. T) s
5 456 M
(his kind of kernel space messaging is a requirement for device clouds which receive and que) s
5 445 M
(ue event interrupts. Another example is the kmemcache system calls/drivers functionality wh) s
5 434 M
(ich allocates/sets/gets/frees kernel memory in a remote cloud node. This is most sought aft) s
5 423 M
(er feature in device clouds than application layer clouds. Userspace clouds cannot control ) s
5 412 M
(remote devices unless some kind of REST/RPC message is sent/received. By implementing RPCs ) s
5 401 M
(within system calls, every cloud node has direct access to remote cloud's kernel memory. It) s
5 390 M
( has to be noted this does not compromise security despite AF_KTLS sockets being still expe) s
5 379 M
(rimental. Because all system calls have processor support for privileged mode execution. Ac) s
5 368 M
(cess to remote kernel memory can happen only by invoking system calls because the memory lo) s
5 357 M
(cations are translated to a unique id in a table privy to system calls and stored in kernel) s
5 346 M
(space. Vulnerability of this communication between kernelspaces is as bad as traditional tr) s
5 335 M
(ansport and there is no additional performance overhead. Even if AF_KTLS is not available i) s
5 324 M
(n near future \(which is OpenSSL integrated into kernel\), messages can be encrypted by users) s
5 313 M
(pace and sent and decrypted in the other end though limited in scope relative to Diffie-Hel) s
5 302 M
(lman SSL handshake. Presently AF_KTLS is available as separate kernel module \(https://netde) s
5 291 M
(vconf.org/1.2/papers/ktls.pdf, https://github.com/ktls/af_ktls\) which exports AF_KTLS socke) s
5 280 M
(t family symbol kernel-wide. Regarding when transport abstraction to kernel and re-emergenc) s
5 269 M
(e to userspace is required, please refer to GlusterFS architecture documentation and diagra) s
5 258 M
(ms at: http://docs.gluster.org/en/latest/Quick-Start-Guide/Architecture/. Diagram for simpl) s
5 247 M
(e file listing ls command is pertinent to this question - ls command originates in userspac) s
5 236 M
(e dives into kernel VFS, is intercepted by FUSE kernel module and is redirected by upcall t) s
5 225 M
(o userspace. All VIRGO linux kernel driver listeners support upcalls to userspace which hav) s
5 214 M
(e downcall-upcall request flow similar to GlusterFS \(NeuronRain RPC is shown in draw.io JGr) s
5 203 M
(aph architecture diagram: https://github.com/shrinivaasanka/Krishna_iResearch_DoxygenDocs/b) s
5 192 M
(lob/master/NeuronRainVIRGOArchitecture.jpg\). GlusterFS is userspace filesystem meant for cl) s
5 181 M
(oud storage. It implements FileSystem in Userspace \(FUSE\) paradigm. Userspace filesystem pe) s
5 170 M
(rforms better than kernelspace per GlusterFS documentation. VIRGO kernel_analytics module d) s
5 159 M
(oes in reverse what FUSE kernel module does in GlusterFS, but for analytics - VIRGO kernel_) s
5 148 M
(analytics reads in realtime, a periodically updated userspace analytics config file and exp) s
5 137 M
(orts into kernel. [EDIT - 21 September 2017, 23 September 2017]: In a Recent Development, K) s
5 126 M
(TLS has been integrated into linux kernel version 4.13 mainline - https://github.com/torval) s
5 115 M
(ds/linux/blob/master/Documentation/networking/tls.txt , https://opensourceforu.com/2017/09/) s
5 104 M
(linux-4-13-enhanced-security/ \). Because of this important feature required for VIRGO cloud) s
5 93 M
( security, all system calls and kernel module listeners of VIRGO64 have been forward ported) s
5 82 M
( to 4.13.3 \(in separate branch - VIRGO_KTLS - https://github.com/shrinivaasanka/virgo64-lin) s
5 71 M
(ux-github-code/tree/VIRGO_KTLS and https://sourceforge.net/p/virgo64-linux/code/ci/VIRGO_KT) s
5 60 M
(LS/tree/\) including KTLS setsockopt\(\) related client-server kernel socket code changes in a) s
5 49 M
( compile time VIRGO_KTLS #ifdef option. This finally makes all VIRGO64 kernelspace systemca) s
5 38 M
(lls-drivers network traffic encrypted. KTLS enabled VIRGO64 is built by including -DVIRGO_K) s
5 27 M
(TLS in system calls and driver Makefiles. Cryptographic handshake information is created by) s
5 16 M
( Userspace libraries like GNUTLS and written in /etc/virgo_ktls.conf key-value pairs \(For G) s
5 5 M
(NUTLS get_record_state the tuples are IV,SequenceNumber,Cipher,Salt\). Wrapper KTLS module d) s
_R
S
%%Page: (18) 18
%%BeginPageSetup
_S
18 36 translate
/pagenum 18 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (18) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(river/virgo/ktls and system calls read /etc/virgo_ktls.conf and set crypto_info for all ker) s
5 731 M
(nel sockets by kernel_setsockopt\(\). By default, VIRGO_KTLS option in Makefiles are commente) s
5 720 M
(d. Every userspace handshake has to overwrite /etc/virgo_ktls.conf. Presently, GNUTLS is no) s
5 709 M
(t tested in kernelspace and only example ktls config crypto_info variables have been export) s
5 698 M
(ed to kernelspace. Master branches of VIRGO64 in both SourceForge and GitHub do not have KT) s
5 687 M
(LS because KTLS is a nascent functionality forcing changes to existing non-TLS kernel socke) s
5 676 M
(ts code flow and does not have public key encryption yet. An alternative to KTLS is to have) s
5 665 M
( fully-secure Virtual Private Network Tunnel clients and servers \(e.g OpenVPN\) across all V) s
5 654 M
(IRGO64 cloud nodes. This secures L2 and L3 TCP/IP by assigning Virtual IP addresses to the ) s
5 643 M
(nodes and all systemcalls-drivers traffic happens across these Virtual IPs within a secure ) s
5 632 M
(Tunnel without KTLS.) s
5 610 M
(**How does machine learning and analytics help in kernel?**) s
5 588 M
(A lot. NeuronRain analytics can learn key-value pairs which can be read by kernel_analytics) s
5 577 M
( kernel module dynamically. Kernel thus is receptive to application layer a feature hithert) s
5 566 M
(o unavailable. Earlier OS drove applications - this is reversed by making applications driv) s
5 555 M
(e kernel behaviour. ) s
5 533 M
(**Are there existing examples of machine learning being used in Linux kernel?**) s
5 511 M
(Yes. There have been some academic research efforts, though not commercial, to write a mach) s
5 500 M
(ine learning scheduler for linux kernel.Linux kernel presently has Completely Fair Schedule) s
5 489 M
(r \(CFS\) which is based on Red-Black Tree insertion and deletion indexed by execution time. ) s
5 478 M
(It is "fair" in the sense it treats running and sleeping) s
5 467 M
(processes equally. If incoming processes are treated as a streaming dataset, a hypothetical) s
5 456 M
( machine learning enabled scheduler could ideally be a "Multilabel Streaming Dataset Classi) s
5 445 M
(fier" partitioning) s
5 434 M
(the incoming processes in the scheduler queue into "Highest,Higher,High,Normal,Low,Lower,Lo) s
5 423 M
(west" priority labels) s
5 412 M
(assigning time slices dynamically according to priority classifier. It is unknown if there ) s
5 401 M
(is a classifier algorithm for streaming datasets \(though there are streaming majority, freq) s
5 390 M
(uency estimator, distinct elements streaming algorithms\). In supervised classification, suc) s
5 379 M
(h algorithm might require some information in the headers of the executables and past histo) s
5 368 M
(ry as training data, neural nets for example. Unsupervised classifier for scheduling \(i.e s) s
5 357 M
(cheduler has zero knowledge about the process\) requires definition of a distance function b) s
5 346 M
(etween processes - similar processes are clustered around a centroid in Voronoi cells. An e) s
5 335 M
(xample distance function between two processes is defined by representing processes on a fe) s
5 324 M
(ature vector space:) s
5 313 M
(        process1 = <pid1, executabletype1, executablename1, size1, cpu_usage1, memory_usage) s
5 302 M
(1, disk_usage1>) s
5 291 M
(        process2 = <pid2, executabletype2, executablename2, size2, cpu_usage2, memory_usage) s
5 280 M
(2, disk_usage2>) s
5 269 M
(        distance\(process1, process2\) = euclidean_distance\(process1, process2\)) s
5 258 M
(Psutils Dictionary Encoding of a process and Diff edit distance between two processes has b) s
5 247 M
(een implemented in https://github.com/shrinivaasanka/asfer-github-code/blob/master/python-s) s
5 236 M
(rc/software_analytics/DeepLearning_SchedulerAnalytics.py. Socket Streaming Analytics Server) s
5 225 M
( of Process Statistics has been implemented in https://github.com/shrinivaasanka/asfer-gith) s
5 214 M
(ub-code/blob/master/python-src/software_analytics/ which analyzes stream of process JSON di) s
5 203 M
(ctionary data and can write out analytics variables read/exported by VIRGO Linux kernel_ana) s
5 192 M
(lytics driver which in turn are readable by OS Scheduler \(requires Scheduler rewrite\). This) s
5 181 M
( is an ideal solution for self-healing OS kernels which learn from process performance in u) s
5 170 M
(serspace and change scheduler behaviour dynamically. Analytics variables can be directly wr) s
5 159 M
(itten to /etc/sysctl.conf or by sysctl  if alternative to /etc/kernel_analytics.conf is pre) s
5 148 M
(ferred. Sysctl has config variables for VM Paging, Scheduler, Networking among others which) s
5 137 M
( are read by kernel live \(kernel.sched.*\)- if kernel provides comprehensive sysctl variable) s
5 126 M
(s for Scheduler policy, it removes necessity for Scheduler rewrite. Presently sysctl appare) s
5 115 M
(ntly exports Round Robin timeslicing only. Similarly, USBmd 32 and 64 bit drivers for Wirel) s
5 104 M
(ess LAN traffic analytics can directly write learnt analytic variables to /etc/sysctl.conf ) s
5 93 M
(\(https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt lists various TCP tuning) s
5 82 M
( configs - net.* - e.g Corking consecutive frequent read/writes into one read/write, SYNACK) s
5 71 M
( retries, fastopen, receive buffer size\). GRAFIT Course Material in https://github.com/shri) s
5 60 M
(nivaasanka/Grafit/blob/c8290348b916e5b35044c3834f56a825b4db23e4/course_material/NeuronRain/) s
5 49 M
(AdvancedComputerScienceAndMachineLearning/AdvancedComputerScienceAndMachineLearning.txt des) s
5 38 M
(cribe an example performance analytics of OS Scheduler \(clockticks-to-processes\) hypothetic) s
5 27 M
(ally implemented as LSH. Simulating this in a linux kernel may not be straightforward. But ) s
5 16 M
(there are performance tools like perf \(http://www.brendangregg.com/perf.html#SchedulerAnaly) s
5 5 M
(sis\) and SAR which can create a streaming text dataset of kernel scheduler runqueue after s) s
_R
S
%%Page: (19) 19
%%BeginPageSetup
_S
18 36 translate
/pagenum 19 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (19) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(ome script processing and write kernel.sched.* variables based on analytics.) s
5 720 M
(**Who can deploy NeuronRain?**) s
5 698 M
(Anyone interested in dynamic analytics driven kernel. For example, realtime IoT kernels ope) s
5 687 M
(rating on smart devices, autonomous driverless vehicles, robots, drones, embedded systems e) s
5 676 M
(tc.,. There are already linux distros for drones and unmanned aerial vehicles \(https://www.) s
5 665 M
(dronecode.org/\) and automotives \(Automotive Grade Linux - https://www.automotivelinux.org/\)) s
5 654 M
(. For example autonomous vehicles and drones have linux kernel drivers for LIDAR sensors fo) s
5 643 M
(r navigation which can be analytics driven. Linux kernel tree has support for LIDAR sensors) s
5 632 M
( and GARMIN GPS USB drivers \(pulsedlight LIDAR driver - https://github.com/torvalds/linux/c) s
5 621 M
(ommits/master/drivers/iio/proximity/pulsedlight-lidar-lite-v2.c, GARMIN GPS USB drivers - h) s
5 610 M
(ttp://elixir.free-electrons.com/linux/latest/source/drivers/usb/serial/garmin_gps.c\). LIDAR) s
5 599 M
( sensor and GPS drivers can import kernel_analytics exported variables - from UAV autopilot) s
5 588 M
(, drone navigation for example. Present implementation of kernel_analytics driver in VIRGO3) s
5 577 M
(2 and VIRGO64 reads /etc/kernel_analytics.conf by VFS kernel functions. In autonomous drivi) s
5 566 M
(ng this file has to be overwritten in high frequency by machine learning userspace code. In) s
5 555 M
(tense File I/O in kernel modules is strongly advised against. Some realtime alternatives to) s
5 544 M
( this have been minimally implemented e.g perpetual reading of analytics variables from a s) s
5 533 M
(treaming socket in a local or remote cloud node in kernelspace - something similar to Spark) s
5 522 M
( Streaming in Kernelspace. This would remove disk latency and necessity for storage of anal) s
5 511 M
(ytics variables - kernel_analytics driver reads the variables from socket and exports them ) s
5 500 M
(kernelwide in an infinite loop. VIRGO64 kernel_analytics module has an optional function im) s
5 489 M
(plemented to read stream of config variable-value pairs connecting to an analytics server a) s
5 478 M
(nd stored in a circular buffer exported kernelwide. For realtime low latency requirements v) s
5 467 M
(iz., autonomous vehicles, patching linux kernel with realtime PREEMPT_RT \(https://git.kerne) s
5 456 M
(l.org/pub/scm/linux/kernel/git/rt/linux-rt-devel.git/tree/\) is suggested \(though this has n) s
5 445 M
(ot been tested\). NeuronRain is a generic machine learning, kernelspace cloud system calls a) s
5 434 M
(nd drivers for analytics powered linux fork-off which integrates cloud and machine learning) s
5 423 M
( features into kernel itself more than being IoT specific e.g ARM has a linux fork-off - ht) s
5 412 M
(tps://github.com/ARM-software/linux and Machine Learning Library based on GoogLeNet Deep Le) s
5 401 M
(arning - https://github.com/ARM-software/ComputeLibrary. Zephyr RTOS Linux supports most of) s
5 390 M
( the IoT boards - https://github.com/zephyrproject-rtos/zephyr - overlaying NeuronRain syst) s
5 379 M
(em calls and drivers source tree on Zephyr is probably the best usecase for kernel analytic) s
5 368 M
(s driven IoT.) s
5 346 M
(**How does NeuronRain compare against other Cloud IoT platforms?**) s
5 324 M
(Prominent cloud platforms for IoT include Google Cloud IoT \(https://cloud.google.com/iot-co) s
5 313 M
(re/\), AWS IoT \(https://aws.amazon.com/iot-platform/\), Microsoft Azure\(https://azure.microso) s
5 302 M
(ft.com/en-in/suites/iot-suite/\) among others. Almost all of these implement an RPC standard) s
5 291 M
( named MQTT \(over TCP/IP stack\) a pub-sub message broker protocol for device-device communi) s
5 280 M
(cations e.g for processing data from sensors connected to cloud. Data from sensors is inges) s
5 269 M
(ted in broker and processed by machine learning analytics. There are Eclipse IoT projects \() s
5 258 M
(https://iot.eclipse.org/\) implementing MQTT protocol for embedded device clouds e.g Mosquit) s
5 247 M
(to \(https://mosquitto.org/\). MQTT pub-sub is in userspace. NeuronRain does not have MQTT an) s
5 236 M
(d implements a system call-to-kernel module kernelspace socket RPC in VIRGO linux, machine ) s
5 225 M
(learning analytics in AsFer and USBmd kernel module and device pub-sub in KingCobra kernel ) s
5 214 M
(module.) s
5 192 M
(**How does MAC electronic money in KingCobra differ from other cryptocurrencies?**) s
5 170 M
(Disclaimer: MAC protocol buffer implementation of a fictitious electronic currency - Neuro ) s
5 159 M
(- in AsFer/KingCobra is an off-shoot of Equilibrium Pricing implementation in KingCobra and) s
5 148 M
( is still evolving \(e.g a minimal proof of work, boost UUID globally unique hashes per prot) s
5 137 M
(ocol buffer currency object have been implemented\). Intent of this fictitious currency is t) s
5 126 M
(o create a virtual economic network e.g Stock Market, Money Market Flow Dynamics, Buy-Sell ) s
5 115 M
(Equilibrium for pricing etc., and draw analytics inferences from them \(e.g Graph Mining\). I) s
5 104 M
(t tries to simulate realworld currency transactions in software by C++ idiom of zero-copy P) s
5 93 M
(erfect Forwarding - only one instance of an object exists globally at any instant - notion ) s
5 82 M
(of singleton added to unique timestamp. This is how currency having unique id flows across ) s
5 71 M
(an economic network in realworld - two copies of a bill create counterfeit - and ideal for ) s
5 60 M
(obliterating double-spending. Traditional cryptocurrencies like bitcoin use blockchain tech) s
5 49 M
(nology - a chronologically increasing linked list of transaction blocks - to maintain a glo) s
5 38 M
(bal ledger of bitcoin transactions which can be lookedup publicly. Mint/Fed in Bitcoin prol) s
5 27 M
(iferates by process of mining SHA hashes having some specific qualities - certain leading d) s
5 16 M
(igits must be 0 and a non-trivial computation has to be performed to attain this least prob) s
5 5 M
(able hashcash - known as Proof-of-Work computation. Bitcoins are awarded based on complexit) s
_R
S
%%Page: (20) 20
%%BeginPageSetup
_S
18 36 translate
/pagenum 20 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (20) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(y of proof-of-work. Bitcoin network hashcash proof-of-work is power intensive requiring hun) s
5 731 M
(dreds of megawatts of electricity. KingCobra MAC currency does not envisage a global transa) s
5 720 M
(ction ledger. It only relies on singleton-ness of a currency object. Every MAC transaction ) s
5 709 M
(is a Client-Server Network Perfect Forwarding which "moves" \(and not copies\) a fictional cu) s
5 698 M
(rrency protocol buffer object over network from sender to receiver \(code for this is in cpp) s
5 687 M
(-src/cloud_move/ directory of AsFer and invoked in a shell script and python transaction co) s
5 676 M
(de in KingCobra. Compile time option -DOPENSSL enables SSL client-server socket transport\).) s
5 665 M
( This global object uniqueness is sufficient for unique spending. Ledgering can be optional) s
5 654 M
(ly implemented by tracking the trail of transactions as a linked list in Currency Protocol ) s
5 643 M
(Buffer. EventNet described in this documentation and implemented in AsFer fits in as global) s
5 632 M
( MAC transaction hyperledger graph where each vertex in EventNet has actors \(Buyers and Sel) s
5 621 M
(lers\) in transaction and direction of edge indicates flow of MAC. Platform neutrality of Pr) s
5 610 M
(otocol Buffer was the reason for its choice as Currency format.) s
5 588 M
(**Is NeuronRain production deployment ready? Is it scalable?**) s
5 566 M
(Presently complete GitHub, GitLab and SourceForge repositories for NeuronRain are contribut) s
5 555 M
(ed \(committed, designed and quality assured\) by a single person without any funding \(K.Srin) s
5 544 M
(ivasan - http://sites.google.com/site/kuja27\) with no team or commercial entity involved in) s
5 533 M
( it. This requires considerable time and effort to write a bug-free code. Though functional) s
5 522 M
(ities are tested sufficiently there could be untested code paths. Automated unit testing fr) s
5 511 M
(amework has not been integrated yet. Note of caution: though significant code has gone in  ) s
5 500 M
(GitHub, GitLab and Sourceforge repositories there is still a lot to be done in terms of cle) s
5 489 M
(aning, documentation, standards, QA etc., So it is upto the end-user to decide. There are n) s
5 478 M
(o scalability benchmarks as of now though some AsFer Spark Cloud implementations - Recursiv) s
5 467 M
(e Gloss Overlap Intrinsic Merit, Computational Geometric Factorization - and Approximate Le) s
5 456 M
(ast Squares SAT Solver have been benchmarked on single node cluster. VIRGO system calls-ker) s
5 445 M
(nel modules transport has been tested on a 2 node cluster. Presently, NeuronRain is almost ) s
5 434 M
(like a beta version. Deployments on large clouds for academic research are encouraged \(e.g ) s
5 423 M
(VIRGO system calls/drivers and kernel analytics for IoT, Spark Recursive Gloss Overlap Inte) s
5 412 M
(rview Intrinsic Merit, Graph Tensor Neuron Network Recursive Lambda Function Growth Intrins) s
5 401 M
(ic Merit, Spark Computational Geometric Factorization on large clusters-specifically Bitoni) s
5 390 M
(c Sort and Local Segment Binary Search, Approximate least squares CNF SAT solver for millio) s
5 379 M
(ns of variables and clauses\). Production/Commercial deployments are subject to caveats and ) s
5 368 M
(licensing terms mentioned in this FAQ.) s
5 346 M
(**Are there any demonstrative tutorial usecases/examples on how NeuronRain VIRGO system cal) s
5 335 M
(ls and drivers work?**) s
5 313 M
(Some reference screen and kernel logs have been committed to:) s
5 302 M
(        - https://github.com/shrinivaasanka/virgo64-linux-github-code/tree/master/virgo-doc) s
5 291 M
(s/systemcalls_drivers) s
5 280 M
(        - https://sourceforge.net/p/virgo64-linux/code/ci/master/tree/virgo-docs/systemcall) s
5 269 M
(s_drivers/) s
5 247 M
(which demonstrate the system call testcases for VIRGO clone, kmemcache and filesystem liste) s
5 236 M
(ner drivers.) s
5 225 M
(virgo-docs/ in URLs above have detailed description of System Calls and Drivers in commit n) s
5 214 M
(otes. VIRGO64 is the 64-bit version of VIRGO repositories but overlay-ed on top of 4.13.3 m) s
5 203 M
(ainline kernel. 64-bit VIRGO kernel has lot of bug fixes and is stabler than 32-bit VIRGO k) s
5 192 M
(ernel. This anomaly between 32 bit 4.1.5 and 64 bit 4.13.3 linux kernels was a frustrating,) s
5 181 M
( deplorable issue to debug. Mainly, 32 bit kernels were frequently crashing in DRM GEM i915) s
5 170 M
( intel graphics drivers. Quite a few i915 bug fixes went in 4.9 and 4.10 kernels which coul) s
5 159 M
(d have been the reason for stabler 64-bit VIRGO kernel. Apart from these testlogs/ or test_) s
5 148 M
(logs/ folders in all NeuronRain repositories contain manually captured testcase logs append) s
5 137 M
(ed with historic date/time stamp suffix. Course material in https://github.com/shrinivaasan) s
5 126 M
(ka/Grafit/tree/master/course_material/NeuronRain have complementary information on NeuronRa) s
5 115 M
(in meant for academic classroom teaching.) s
5 93 M
(**How is NeuronRain code licensed? Can it be used commercially? Is technical support availa) s
5 82 M
(ble?**) s
5 60 M
(All repositories of NeuronRain \(in Sourceforge, GitLab and GitHub\) excluding Grafit course ) s
5 49 M
(materials \(https://github.com/shrinivaasanka/Grafit/ - replicated in SourceForge and GitLab) s
5 38 M
( - which is Creative Commons 4.0 licensed\) are GPLv3 copyleft licensed. As per license term) s
5 27 M
(s, NeuronRain code has no warranty. Any commercial derivative is subject to clauses of GPLv) s
5 16 M
(3 copyleft licensing. Please refer to https://www.gnu.org/licenses/gpl-faq.html#GPLCommerci) s
5 5 M
(ally for licensing terms for commercial derivatives \("Free means freedom, not price"\). GPLv) s
_R
S
%%Page: (21) 21
%%BeginPageSetup
_S
18 36 translate
/pagenum 21 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (21) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(3 copyleft license mandates any derived source code to be open sourced \(Sections on Conveyi) s
5 731 M
(ng Verbatim Copies, Conveying Modified Source and Non-Source versions - https://www.gnu.org) s
5 720 M
(/licenses/gpl-3.0.en.html\). Present model followed is as below) s
5 709 M
(        \(*\) NeuronRain repositories also have implementations of author's publications and ) s
5 698 M
(drafts - respective GPLv3 and Creative Commons 4.0 NCND clauses apply) s
5 687 M
(        \(*\) Premium Technical support for NeuronRain codebases is provided only on direct r) s
5 676 M
(equest based on feasibility and time constraints.) s
5 665 M
(        \(*\) GPLv3 license terms do not prohibit pricing.) s
5 654 M
(        \(*\) Commercial derivatives \(for individuals or organizations who clone NeuronRain r) s
5 643 M
(epositories and make modifications for commercial use\) if any have to be GPLv3 copyleft and) s
5 632 M
( Creative Commons 4.0 NCND compliant.) s
5 610 M
(**What is dual licensing?**) s
5 588 M
(Closedsource, proprietary, premium version derived and completeley different from NeuronRai) s
5 577 M
(n Open Source codebases is in research, architecture and development and has quite a few ad) s
5 566 M
(vanced features but it is not commercially available. Only opensource codebases of NeuronRa) s
5 555 M
(in in SourceForge,GitHub and GitLab are copyleft licensed under GPL v3 and Creative Commons) s
5 544 M
( 4.0 NCND. Dual licensing implies dichotomous licensing - NeuronRain is free \(open\) and fre) s
5 533 M
(e \(without price\) while Closedsource is at premium.) s
5 511 M
(**Who owns NeuronRain repositories?**) s
5 489 M
(NeuronRain GitHub, GitLab and SourceForge repositories licenses for Krishna iResearch Open ) s
5 478 M
(Source Products repositories at:) s
5 467 M
(http://sourceforge.net/users/ka_shrinivaasan,) s
5 456 M
(https://github.com/shrinivaasanka,) s
5 445 M
(https://gitlab.com/shrinivaasanka,) s
5 434 M
(https://www.openhub.net/accounts/ka_shrinivaasan) s
5 423 M
(Krishna iResearch GitHub Organization: https://github.com/Krishna-iResearch) s
5 412 M
(Personal website\(research\): https://sites.google.com/site/kuja27/ \(Mirrored at https://gith) s
5 401 M
(ub.com/shrinivaasanka/Krishna_iResearch_DoxygenDocs/blob/master/kuja27_website_mirrored/sit) s
5 390 M
(e/kuja27/ and similar relative paths in GitLab and SourceForge\)) s
5 368 M
(**are owned by:**) s
5 346 M
(P.R.S.Kannan and Alamelu Kannan \(alias Rukmini Kannan\),) s
5 335 M
(172, Gandhi Adigal Salai,) s
5 324 M
(Kumbakonam - 612001.) s
5 313 M
(Tamil Nadu, India.) s
5 291 M
(Creative Commons 4.0 No Derivatives Non Commercial for NeuronRain SourceForge, GitHub and G) s
5 280 M
(itLab Grafit Open Learning Course Notes: https://github.com/shrinivaasanka/Krishna_iResearc) s
5 269 M
(h_DoxygenDocs/blob/master/Creative%20Commons%20%E2%80%94%20Attribution-NonCommercial-NoDeri) s
5 258 M
(vatives%204.0%20International%20%E2%80%94%20CC%20BY-NC-ND%204.0.html \(replicated in SourceF) s
5 247 M
(orge and GitLab\)) s
5 225 M
(GPL v3.0 for other NeuronRain GitLab, GitHub and SourceForge repositories: https://github.c) s
5 214 M
(om/shrinivaasanka/Krishna_iResearch_DoxygenDocs/blob/master/The%20GNU%20General%20Public%20) s
5 203 M
(License%20v3.0%20-%20GNU%20Project%20-%20Free%20Software%20Foundation%20\(FSF\).html) s
5 181 M
(Previous license ownership attribution supersedes all other copyleft notice headers within ) s
5 170 M
(NeuronRain GitLab, GitHub and SourceForge source code files.) s
5 148 M
(**and contributed by:**) s
5 126 M
(K.Srinivasan) s
5 115 M
(S/O.P.R.S.Kannan,) s
5 104 M
(\(also known as: Shrinivaasan Kannan, Shrinivas Kannan\)) s
5 93 M
(172, Gandhi Adigal Salai,) s
5 82 M
(Kumbakonam - 612001.) s
5 71 M
(Tamil Nadu, India.) s
5 60 M
(SourceForge/GitHub/GitLab Repository email: grafitopenlearning@gmail.com) s
5 49 M
(Personal emails: ka.shrinivaasan@gmail.com, shrinivas.kannan@gmail.com, kashrinivaasan@live) s
5 38 M
(.com) s
5 27 M
(NeuronRain mailing lists: https://sourceforge.net/p/virgo-linux/mailman/virgo-linux-mailing) s
5 16 M
(-list/, https://in.groups.yahoo.com/neo/groups/grafitopenlearning/info) s
_R
S
%%Page: (22) 22
%%BeginPageSetup
_S
18 36 translate
/pagenum 22 def
/fname (index.rst) def
/fdir (.) def
/ftail (index.rst) def
% User defined strings:
/fmodstr (Wed Aug 21 15:49:10 2019) def
/pagenumstr (22) def
/user_header_p false def
/user_footer_p false def
%%EndPageSetup
do_header
5 742 M
(Contributor has no industry or academic affiliations and does not accrue any monetary benef) s
5 731 M
(it and the whole opensource effort is a charity. Name "Krishna iResearch" is non-funded, no) s
5 720 M
(t a commercially registered entity but only a profile name registered in SourceForge and la) s
5 709 M
(ter in GitHub and GitLab. Because of certain cybercrimes, mistaken identity and copyleft vi) s
5 698 M
(olation problems in the past \(and possibility of a signature forgery too which I neither co) s
5 687 M
(nfirm nor deny\), sumptuous id proofs of the author have been uploaded to https://sourceforg) s
5 676 M
(e.net/projects/acadpdrafts/files/ and https://sites.google.com/site/kuja27/CV_of_Srinivasan) s
5 665 M
(Kannan_alias_KaShrinivaasan_alias_ShrinivasKannan.pdf) s
5 643 M
(**How applicable is NeuronRain for Drones/Robots?**) s
5 621 M
(Drones have distinct software and hardware for mission plan \(route map\), flight and ground ) s
5 610 M
(control often different from mainstream linux kernel. Mission plans are uploaded to drone b) s
5 599 M
(y special protocols like MAVlink and userspace SDKs are available for it. Drone control use) s
5 588 M
(rspace C++ code example in https://github.com/Dronecode/DronecodeSDK/blob/develop/example/f) s
5 577 M
(ly_qgc_mission/fly_qgc_mission.cpp uses DronecodeSDK in userspace and there is no necessity) s
5 566 M
( for kernel_analytics kernel module to read analytics variables into kernelspace from users) s
5 555 M
(pace Machine Learning code. Application code can directly instantiate /etc/kernel_analytics) s
5 544 M
(.conf File locally/Socket Streaming Iterable in https://gitlab.com/shrinivaasanka/asfer-git) s
5 533 M
(hub-code/blob/master/python-src/Streaming_AbstractGenerator.py on a remote host and at port) s
5 522 M
( 64001 \(in Python\) and read analytics variables for drone navigation augmenting flight plan) s
5 511 M
( - Quite useful when static mission plans require dynamic changes after upload to drone e.g) s
5 500 M
( Military Reconnaissance, Autonomous Combat, Autonomous Online Shopping Delivery. For robot) s
5 489 M
(s, there are already linux add-on operating systems in development e.g ROS - http://www.ros) s
5 478 M
(.org/ which could benefit by kernel_analytics and VIRGO32/VIRGO64 system calls and drivers.) s
5 467 M
( Recent linux kernel versions from 4.17.x onwards support PhoenixRC flight controller \(http) s
5 456 M
(s://github.com/torvalds/linux/blob/master/drivers/input/joystick/pxrc.c\) and thus drone tel) s
5 445 M
(emetry is part of linux kernel. Kernel Analytics navigation variables exported by VIRGO32 a) s
5 434 M
(nd VIRGO64 kernel_analytics drivers can be imported in pxrc drone driver and input_set_abs_) s
5 423 M
(params\(\) is invoked for appropriate setting of ordinates, rudder, throttle values. ) s
5 412 M
( ) s
5 401 M
(**Can NeuronRain be deployed on Mobile processors?**) s
5 379 M
(Presently mobile OSes are not supported. But that should not be difficult. Similar to Andro) s
5 368 M
(id which is a linux variant, NeuronRain can be cross-compiled for a mobile architecture.) s
5 346 M
(**Are there any realworld usecases for applicability of machine learning in linux kernel?**) s
5 324 M
(Yes. Some usecases are described in  https://github.com/shrinivaasanka/Grafit/blob/master/E) s
5 313 M
(nterpriseAnalytics_with_NeuronRain.pdf. Apart from these, Pagefault data and on-demand pagi) s
5 302 M
(ng reference pattern for each application can be analyzed for unusual behaviour and malware) s
5 291 M
( infection. Malware have abnormal address reference patterns than usual applications.) s
_R
S
%%Trailer
%%Pages: 22
%%DocumentNeededResources: font Courier-Bold Courier 
%%EOF
